{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr 16 01:49:15 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A10G         On   | 00000000:00:1E.0 Off |                    0 |\n",
      "|  0%   35C    P0    62W / 300W |  18849MiB / 23028MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      7813      C   ...vs/pytorch_p39/bin/python    18843MiB |\n",
      "+-----------------------------------------------------------------------------+\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: prefetch_generator in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (1.0.3)\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: timm in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (0.6.13)\n",
      "Requirement already satisfied: huggingface-hub in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from timm) (0.13.4)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from timm) (0.14.1)\n",
      "Requirement already satisfied: torch>=1.7 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from timm) (1.13.1)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from timm) (5.4.1)\n",
      "Requirement already satisfied: typing_extensions in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from torch>=1.7->timm) (4.4.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface-hub->timm) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface-hub->timm) (21.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface-hub->timm) (4.63.2)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface-hub->timm) (3.6.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from torchvision->timm) (1.23.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from torchvision->timm) (9.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->huggingface-hub->timm) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->huggingface-hub->timm) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->huggingface-hub->timm) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->huggingface-hub->timm) (2022.12.7)\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting albumentations\n",
      "  Downloading albumentations-1.3.0-py3-none-any.whl (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting opencv-python-headless>=4.1.1\n",
      "  Downloading opencv_python_headless-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-image>=0.16.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from albumentations) (0.19.3)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from albumentations) (1.8.1)\n",
      "Requirement already satisfied: PyYAML in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from albumentations) (5.4.1)\n",
      "Collecting qudida>=0.0.4\n",
      "  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from albumentations) (1.23.5)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from qudida>=0.0.4->albumentations) (4.4.0)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from qudida>=0.0.4->albumentations) (1.0)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (2.16.2)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (2022.10.10)\n",
      "Requirement already satisfied: networkx>=2.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (3.0)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (9.2.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (1.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from packaging>=20.0->scikit-image>=0.16.1->albumentations) (3.0.9)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n",
      "Installing collected packages: opencv-python-headless, qudida, albumentations\n",
      "Successfully installed albumentations-1.3.0 opencv-python-headless-4.7.0.72 qudida-0.0.4\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "!pip install prefetch_generator\n",
    "!pip install timm\n",
    "!pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "import torchvision\n",
    "import boto3\n",
    "import io\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import tempfile\n",
    "import PIL\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from prefetch_generator import BackgroundGenerator\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're using: cuda\n"
     ]
    }
   ],
   "source": [
    "# Make sure you're using cuda (GPU) by checking the hardware accelerator under Runtime -> Change runtime type\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"We're using:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Download dataset from AWS S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install cloudpathlib[s3,gs,azure]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from cloudpathlib import CloudPath\n",
    "\n",
    "#Download all the files from AWS S3\n",
    "#Run this cell once if working in a new sagemaker instance\n",
    "#This will take about 45 minutes to finish\n",
    "#Use ls -l | grep \"^-\" | wc -l in terminal to check the number of files\n",
    "\n",
    "#cp = CloudPath(\"s3://cassavaproject\")\n",
    "#cp.download_to(\"Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, transform=None):\n",
    "        self.image_path = 'Dataset/train_images'\n",
    "        self.labels = pd.read_csv('Dataset/train.csv')\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        img_name = self.image_path + '/' + self.labels.iloc[idx]['image_id']\n",
    "\n",
    "        # Read the image from the file path\n",
    "        #image = Image.open(img_name)\n",
    "        image = cv2.imread(img_name)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        #image = torchvision.io.read_file(img_name)\n",
    "        #image = torchvision.io.decode_jpeg(image, device=\"cpu\")\n",
    "        #image = image.float().\n",
    "        \n",
    "        # Transform the image using self.transform\n",
    "        if self.transform:\n",
    "            image = image = self.transform(image=image)[\"image\"]\n",
    "\n",
    "        if \"label\" in self.labels.columns:\n",
    "            label = self.labels.iloc[idx]['label']\n",
    "            sample = (image, label)\n",
    "        else:\n",
    "            sample = (image)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Used for directly download and read file from AWS S3.\n",
    "#If running the download cell above, use 'MyDataset' class instead of this one.\n",
    "class MyDatasetS3(Dataset):\n",
    "\n",
    "    def __init__(self, transform=None):\n",
    "        #File path for csv and images\n",
    "        self.image_path = 'train_images'\n",
    "        \n",
    "        #Connect to s3 file\n",
    "        self.csv_path = 'train.csv'\n",
    "        self.s3_client = boto3.resource('s3')\n",
    "        self.bucket = self.s3_client.Bucket('cassavaproject')\n",
    "        \n",
    "        s3 = boto3.client('s3')\n",
    "        obj = s3.get_object(Bucket = 'cassavaproject',Key = 'train.csv')\n",
    "\n",
    "        self.labels = pd.read_csv(obj['Body'])\n",
    "        \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        img_name = self.image_path + '/' + self.labels.iloc[idx]['image_id']\n",
    "        \n",
    "        # we can download the file from S3 to a temporary file locally, then store that opened file as our image variable.\n",
    "        # we need to create the local file name\n",
    "        obj = self.bucket.Object(img_name)\n",
    "        tmp = tempfile.NamedTemporaryFile()\n",
    "        tmp_name = '{}.jpg'.format(tmp.name)\n",
    "\n",
    "        # now we can actually download from S3 to a local place\n",
    "        with open(tmp_name, 'wb') as f:\n",
    "            obj.download_fileobj(f)\n",
    "            f.flush()\n",
    "            f.close()\n",
    "            \n",
    "            image = torchvision.io.read_file(tmp_name)\n",
    "            image = torchvision.io.decode_jpeg(image, device=\"cpu\")\n",
    "            image = image.float()\n",
    "            \n",
    "        # Transform the image using self.transform\n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "\n",
    "        if \"label\" in self.labels.columns:\n",
    "            label = self.labels.iloc[idx]['label']\n",
    "            sample = (image, label)\n",
    "        else:\n",
    "            sample = (image)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Credit: https://www.kaggle.com/code/aliabdin1/calculate-mean-std-of-images/notebook\n",
    "mean = np.array([0.42984136, 0.49624753, 0.3129598 ])\n",
    "std = np.array([0.21417203, 0.21910103, 0.19542212])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transform = torch.nn.Sequential(transforms.Resize((256,256),antialias=True), transforms.Normalize(mean=mean,\n",
    "    std=std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "albu_transform = A.Compose(\n",
    "        [A.CenterCrop(height=256, width=256), \n",
    "         A.RandomBrightnessContrast(p=0.5), \n",
    "         A.Normalize(mean=mean, std=std),\n",
    "         ToTensorV2()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = MyDataset(transform=albu_transform)\n",
    "train_data, test_data = torch.utils.data.random_split(dataset, [15000, 6397])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['repvgg_a2',\n",
       " 'repvgg_b0',\n",
       " 'repvgg_b1',\n",
       " 'repvgg_b1g4',\n",
       " 'repvgg_b2',\n",
       " 'repvgg_b2g4',\n",
       " 'repvgg_b3',\n",
       " 'repvgg_b3g4',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.list_models('*vgg*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'https://download.pytorch.org/models/vgg16-397923af.pth',\n",
       " 'num_classes': 1000,\n",
       " 'input_size': (3, 224, 224),\n",
       " 'pool_size': (7, 7),\n",
       " 'crop_pct': 0.875,\n",
       " 'interpolation': 'bilinear',\n",
       " 'mean': (0.485, 0.456, 0.406),\n",
       " 'std': (0.229, 0.224, 0.225),\n",
       " 'first_conv': 'features.0',\n",
       " 'classifier': 'head.fc',\n",
       " 'architecture': 'vgg16'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model = timm.create_model('vgg16', pretrained=True)\n",
    "test_model.default_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class OurModel(nn.Module):\n",
    "  def __init__(self, num_classes):\n",
    "    super(OurModel, self).__init__()\n",
    "    self.model = timm.create_model('vgg19', pretrained=True)#torchvision.models.resnet34(weights='IMAGENET1K_V1')\n",
    "    self.model.head.fc = nn.Linear(self.model.head.fc.in_features, num_classes)\n",
    "    self.softmax = nn.Softmax()\n",
    "\n",
    "  def forward(self, input):\n",
    "    out = self.model(input)\n",
    "    softmax = self.softmax(out)\n",
    "    return softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /home/ec2-user/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n"
     ]
    }
   ],
   "source": [
    "model = OurModel(5).cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=1e-6, amsgrad=False) #torch.optim.Adam(model.parameters(), lr=5*1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataLoaderX(DataLoader):\n",
    "\n",
    "    def __iter__(self):\n",
    "        return BackgroundGenerator(super().__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoaderX(dataset=train_data, batch_size = 128, shuffle= True, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoaderX(dataset=test_data, batch_size = 128, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fine-tuning...\n"
     ]
    }
   ],
   "source": [
    "print('Start fine-tuning...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    #model = torch.compile(model)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "            outputs = model(images)\n",
    "            \n",
    "            _,prediction = torch.max(outputs.data, 1)\n",
    "            correct += (prediction == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        model.train()\n",
    "        return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_run_time(start_time):\n",
    "    end_time = time.time()\n",
    "    runtime = end_time - start_time\n",
    "    return runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7813/457301256.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  softmax = self.softmax(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25]: Iter 1, Loss 1.8623, Runtime 0m 3s\n",
      "Epoch [1/25]: Iter 2, Loss 1.3345, Runtime 0m 4s\n",
      "Epoch [1/25]: Iter 3, Loss 1.2330, Runtime 0m 5s\n",
      "Epoch [1/25]: Iter 4, Loss 1.2798, Runtime 0m 6s\n",
      "Epoch [1/25]: Iter 5, Loss 1.2876, Runtime 0m 7s\n",
      "Epoch [1/25]: Iter 6, Loss 1.2798, Runtime 0m 8s\n",
      "Epoch [1/25]: Iter 7, Loss 1.2642, Runtime 0m 9s\n",
      "Epoch [1/25]: Iter 8, Loss 1.3189, Runtime 0m 11s\n",
      "Epoch [1/25]: Iter 9, Loss 1.2955, Runtime 0m 12s\n",
      "Epoch [1/25]: Iter 10, Loss 1.3189, Runtime 0m 13s\n",
      "Epoch [1/25]: Iter 11, Loss 1.3345, Runtime 0m 14s\n",
      "Epoch [1/25]: Iter 12, Loss 1.3111, Runtime 0m 15s\n",
      "Epoch [1/25]: Iter 13, Loss 1.2798, Runtime 0m 16s\n",
      "Epoch [1/25]: Iter 14, Loss 1.3267, Runtime 0m 17s\n",
      "Epoch [1/25]: Iter 15, Loss 1.3189, Runtime 0m 18s\n",
      "Epoch [1/25]: Iter 16, Loss 1.2955, Runtime 0m 20s\n",
      "Epoch [1/25]: Iter 17, Loss 1.3580, Runtime 0m 21s\n",
      "Epoch [1/25]: Iter 18, Loss 1.2798, Runtime 0m 22s\n",
      "Epoch [1/25]: Iter 19, Loss 1.3501, Runtime 0m 23s\n",
      "Epoch [1/25]: Iter 20, Loss 1.2876, Runtime 0m 24s\n",
      "Epoch [1/25]: Iter 21, Loss 1.3267, Runtime 0m 25s\n",
      "Epoch [1/25]: Iter 22, Loss 1.3580, Runtime 0m 26s\n",
      "Epoch [1/25]: Iter 23, Loss 1.2720, Runtime 0m 28s\n",
      "Epoch [1/25]: Iter 24, Loss 1.3267, Runtime 0m 29s\n",
      "Epoch [1/25]: Iter 25, Loss 1.3736, Runtime 0m 30s\n",
      "Epoch [1/25]: Iter 26, Loss 1.2720, Runtime 0m 31s\n",
      "Epoch [1/25]: Iter 27, Loss 1.2642, Runtime 0m 32s\n",
      "Epoch [1/25]: Iter 28, Loss 1.2876, Runtime 0m 33s\n",
      "Epoch [1/25]: Iter 29, Loss 1.2798, Runtime 0m 34s\n",
      "Epoch [1/25]: Iter 30, Loss 1.3267, Runtime 0m 35s\n",
      "Epoch [1/25]: Iter 31, Loss 1.2876, Runtime 0m 37s\n",
      "Epoch [1/25]: Iter 32, Loss 1.2798, Runtime 0m 38s\n",
      "Epoch [1/25]: Iter 33, Loss 1.3736, Runtime 0m 39s\n",
      "Epoch [1/25]: Iter 34, Loss 1.2564, Runtime 0m 40s\n",
      "Epoch [1/25]: Iter 35, Loss 1.2564, Runtime 0m 41s\n",
      "Epoch [1/25]: Iter 36, Loss 1.2955, Runtime 0m 42s\n",
      "Epoch [1/25]: Iter 37, Loss 1.2876, Runtime 0m 43s\n",
      "Epoch [1/25]: Iter 38, Loss 1.2564, Runtime 0m 44s\n",
      "Epoch [1/25]: Iter 39, Loss 1.2955, Runtime 0m 46s\n",
      "Epoch [1/25]: Iter 40, Loss 1.2486, Runtime 0m 47s\n",
      "Epoch [1/25]: Iter 41, Loss 1.2876, Runtime 0m 48s\n",
      "Epoch [1/25]: Iter 42, Loss 1.2251, Runtime 0m 49s\n",
      "Epoch [1/25]: Iter 43, Loss 1.2564, Runtime 0m 50s\n",
      "Epoch [1/25]: Iter 44, Loss 1.2173, Runtime 0m 51s\n",
      "Epoch [1/25]: Iter 45, Loss 1.3736, Runtime 0m 52s\n",
      "Epoch [1/25]: Iter 46, Loss 1.3501, Runtime 0m 53s\n",
      "Epoch [1/25]: Iter 47, Loss 1.2408, Runtime 0m 55s\n",
      "Epoch [1/25]: Iter 48, Loss 1.2720, Runtime 0m 56s\n",
      "Epoch [1/25]: Iter 49, Loss 1.2720, Runtime 0m 57s\n",
      "Epoch [1/25]: Iter 50, Loss 1.2798, Runtime 0m 58s\n",
      "Epoch [1/25]: Iter 51, Loss 1.2642, Runtime 0m 59s\n",
      "Epoch [1/25]: Iter 52, Loss 1.2564, Runtime 1m 0s\n",
      "Epoch [1/25]: Iter 53, Loss 1.3111, Runtime 1m 1s\n",
      "Epoch [1/25]: Iter 54, Loss 1.1626, Runtime 1m 2s\n",
      "Epoch [1/25]: Iter 55, Loss 1.3345, Runtime 1m 4s\n",
      "Epoch [1/25]: Iter 56, Loss 1.2330, Runtime 1m 5s\n",
      "Epoch [1/25]: Iter 57, Loss 1.2798, Runtime 1m 6s\n",
      "Epoch [1/25]: Iter 58, Loss 1.3033, Runtime 1m 7s\n",
      "Epoch [1/25]: Iter 59, Loss 1.3111, Runtime 1m 8s\n",
      "Epoch [1/25]: Iter 60, Loss 1.3423, Runtime 1m 9s\n",
      "Epoch [1/25]: Iter 61, Loss 1.1861, Runtime 1m 10s\n",
      "Epoch [1/25]: Iter 62, Loss 1.2876, Runtime 1m 11s\n",
      "Epoch [1/25]: Iter 63, Loss 1.3111, Runtime 1m 13s\n",
      "Epoch [1/25]: Iter 64, Loss 1.2251, Runtime 1m 14s\n",
      "Epoch [1/25]: Iter 65, Loss 1.3501, Runtime 1m 15s\n",
      "Epoch [1/25]: Iter 66, Loss 1.3345, Runtime 1m 16s\n",
      "Epoch [1/25]: Iter 67, Loss 1.3580, Runtime 1m 17s\n",
      "Epoch [1/25]: Iter 68, Loss 1.1783, Runtime 1m 18s\n",
      "Epoch [1/25]: Iter 69, Loss 1.3033, Runtime 1m 19s\n",
      "Epoch [1/25]: Iter 70, Loss 1.2408, Runtime 1m 21s\n",
      "Epoch [1/25]: Iter 71, Loss 1.3111, Runtime 1m 22s\n",
      "Epoch [1/25]: Iter 72, Loss 1.2408, Runtime 1m 23s\n",
      "Epoch [1/25]: Iter 73, Loss 1.2798, Runtime 1m 24s\n",
      "Epoch [1/25]: Iter 74, Loss 1.3267, Runtime 1m 25s\n",
      "Epoch [1/25]: Iter 75, Loss 1.2095, Runtime 1m 26s\n",
      "Epoch [1/25]: Iter 76, Loss 1.2642, Runtime 1m 27s\n",
      "Epoch [1/25]: Iter 77, Loss 1.2720, Runtime 1m 28s\n",
      "Epoch [1/25]: Iter 78, Loss 1.3033, Runtime 1m 30s\n",
      "Epoch [1/25]: Iter 79, Loss 1.2720, Runtime 1m 31s\n",
      "Epoch [1/25]: Iter 80, Loss 1.2330, Runtime 1m 32s\n",
      "Epoch [1/25]: Iter 81, Loss 1.3111, Runtime 1m 33s\n",
      "Epoch [1/25]: Iter 82, Loss 1.3501, Runtime 1m 34s\n",
      "Epoch [1/25]: Iter 83, Loss 1.2642, Runtime 1m 35s\n",
      "Epoch [1/25]: Iter 84, Loss 1.3423, Runtime 1m 36s\n",
      "Epoch [1/25]: Iter 85, Loss 1.2720, Runtime 1m 37s\n",
      "Epoch [1/25]: Iter 86, Loss 1.2720, Runtime 1m 39s\n",
      "Epoch [1/25]: Iter 87, Loss 1.2017, Runtime 1m 40s\n",
      "Epoch [1/25]: Iter 88, Loss 1.3111, Runtime 1m 41s\n",
      "Epoch [1/25]: Iter 89, Loss 1.2720, Runtime 1m 42s\n",
      "Epoch [1/25]: Iter 90, Loss 1.3423, Runtime 1m 43s\n",
      "Epoch [1/25]: Iter 91, Loss 1.3189, Runtime 1m 44s\n",
      "Epoch [1/25]: Iter 92, Loss 1.3345, Runtime 1m 45s\n",
      "Epoch [1/25]: Iter 93, Loss 1.2642, Runtime 1m 46s\n",
      "Epoch [1/25]: Iter 94, Loss 1.3267, Runtime 1m 48s\n",
      "Epoch [1/25]: Iter 95, Loss 1.2642, Runtime 1m 49s\n",
      "Epoch [1/25]: Iter 96, Loss 1.2173, Runtime 1m 50s\n",
      "Epoch [1/25]: Iter 97, Loss 1.3580, Runtime 1m 51s\n",
      "Epoch [1/25]: Iter 98, Loss 1.2955, Runtime 1m 52s\n",
      "Epoch [1/25]: Iter 99, Loss 1.3345, Runtime 1m 53s\n",
      "Epoch [1/25]: Iter 100, Loss 1.2955, Runtime 1m 54s\n",
      "Epoch [1/25]: Iter 101, Loss 1.2642, Runtime 1m 55s\n",
      "Epoch [1/25]: Iter 102, Loss 1.3345, Runtime 1m 57s\n",
      "Epoch [1/25]: Iter 103, Loss 1.4048, Runtime 1m 58s\n",
      "Epoch [1/25]: Iter 104, Loss 1.2564, Runtime 1m 59s\n",
      "Epoch [1/25]: Iter 105, Loss 1.3111, Runtime 1m 60s\n",
      "Epoch [1/25]: Iter 106, Loss 1.3423, Runtime 2m 1s\n",
      "Epoch [1/25]: Iter 107, Loss 1.2486, Runtime 2m 2s\n",
      "Epoch [1/25]: Iter 108, Loss 1.3267, Runtime 2m 3s\n",
      "Epoch [1/25]: Iter 109, Loss 1.3501, Runtime 2m 4s\n",
      "Epoch [1/25]: Iter 110, Loss 1.2486, Runtime 2m 6s\n",
      "Epoch [1/25]: Iter 111, Loss 1.3736, Runtime 2m 7s\n",
      "Epoch [1/25]: Iter 112, Loss 1.3501, Runtime 2m 8s\n",
      "Epoch [1/25]: Iter 113, Loss 1.2720, Runtime 2m 9s\n",
      "Epoch [1/25]: Iter 114, Loss 1.3501, Runtime 2m 10s\n",
      "Epoch [1/25]: Iter 115, Loss 1.2564, Runtime 2m 11s\n",
      "Epoch [1/25]: Iter 116, Loss 1.1861, Runtime 2m 12s\n",
      "Epoch [1/25]: Iter 117, Loss 1.3111, Runtime 2m 14s\n",
      "Epoch [1/25]: Iter 118, Loss 1.2798, Runtime 2m 14s\n",
      "Testing on test dataset...\n",
      "Epoch [1/25] Loss: 153.0166 Train_Acc: 60.7933  Test_Acc: 61.8415\n",
      "The accuracy is improved, save model\n",
      "Epoch [2/25]: Iter 1, Loss 1.2330, Runtime 2m 50s\n",
      "Epoch [2/25]: Iter 2, Loss 1.3189, Runtime 2m 51s\n",
      "Epoch [2/25]: Iter 3, Loss 1.2798, Runtime 2m 52s\n",
      "Epoch [2/25]: Iter 4, Loss 1.3033, Runtime 2m 53s\n",
      "Epoch [2/25]: Iter 5, Loss 1.3111, Runtime 2m 54s\n",
      "Epoch [2/25]: Iter 6, Loss 1.3033, Runtime 2m 55s\n",
      "Epoch [2/25]: Iter 7, Loss 1.2564, Runtime 2m 57s\n",
      "Epoch [2/25]: Iter 8, Loss 1.2955, Runtime 2m 58s\n",
      "Epoch [2/25]: Iter 9, Loss 1.3111, Runtime 2m 59s\n",
      "Epoch [2/25]: Iter 10, Loss 1.2486, Runtime 2m 60s\n",
      "Epoch [2/25]: Iter 11, Loss 1.2642, Runtime 3m 1s\n",
      "Epoch [2/25]: Iter 12, Loss 1.2642, Runtime 3m 2s\n",
      "Epoch [2/25]: Iter 13, Loss 1.3580, Runtime 3m 3s\n",
      "Epoch [2/25]: Iter 14, Loss 1.2642, Runtime 3m 4s\n",
      "Epoch [2/25]: Iter 15, Loss 1.3111, Runtime 3m 6s\n",
      "Epoch [2/25]: Iter 16, Loss 1.3501, Runtime 3m 7s\n",
      "Epoch [2/25]: Iter 17, Loss 1.3736, Runtime 3m 8s\n",
      "Epoch [2/25]: Iter 18, Loss 1.2798, Runtime 3m 9s\n",
      "Epoch [2/25]: Iter 19, Loss 1.2876, Runtime 3m 10s\n",
      "Epoch [2/25]: Iter 20, Loss 1.3033, Runtime 3m 11s\n",
      "Epoch [2/25]: Iter 21, Loss 1.2642, Runtime 3m 12s\n",
      "Epoch [2/25]: Iter 22, Loss 1.2642, Runtime 3m 13s\n",
      "Epoch [2/25]: Iter 23, Loss 1.3501, Runtime 3m 15s\n",
      "Epoch [2/25]: Iter 24, Loss 1.3423, Runtime 3m 16s\n",
      "Epoch [2/25]: Iter 25, Loss 1.2798, Runtime 3m 17s\n",
      "Epoch [2/25]: Iter 26, Loss 1.3189, Runtime 3m 18s\n",
      "Epoch [2/25]: Iter 27, Loss 1.2720, Runtime 3m 19s\n",
      "Epoch [2/25]: Iter 28, Loss 1.2564, Runtime 3m 20s\n",
      "Epoch [2/25]: Iter 29, Loss 1.2955, Runtime 3m 21s\n",
      "Epoch [2/25]: Iter 30, Loss 1.2876, Runtime 3m 22s\n",
      "Epoch [2/25]: Iter 31, Loss 1.2876, Runtime 3m 24s\n",
      "Epoch [2/25]: Iter 32, Loss 1.2798, Runtime 3m 25s\n",
      "Epoch [2/25]: Iter 33, Loss 1.2955, Runtime 3m 26s\n",
      "Epoch [2/25]: Iter 34, Loss 1.2330, Runtime 3m 27s\n",
      "Epoch [2/25]: Iter 35, Loss 1.2720, Runtime 3m 28s\n",
      "Epoch [2/25]: Iter 36, Loss 1.3111, Runtime 3m 29s\n",
      "Epoch [2/25]: Iter 37, Loss 1.1939, Runtime 3m 30s\n",
      "Epoch [2/25]: Iter 38, Loss 1.3345, Runtime 3m 32s\n",
      "Epoch [2/25]: Iter 39, Loss 1.3658, Runtime 3m 33s\n",
      "Epoch [2/25]: Iter 40, Loss 1.2798, Runtime 3m 34s\n",
      "Epoch [2/25]: Iter 41, Loss 1.3111, Runtime 3m 35s\n",
      "Epoch [2/25]: Iter 42, Loss 1.1861, Runtime 3m 36s\n",
      "Epoch [2/25]: Iter 43, Loss 1.3033, Runtime 3m 37s\n",
      "Epoch [2/25]: Iter 44, Loss 1.2955, Runtime 3m 38s\n",
      "Epoch [2/25]: Iter 45, Loss 1.3111, Runtime 3m 39s\n",
      "Epoch [2/25]: Iter 46, Loss 1.3033, Runtime 3m 41s\n",
      "Epoch [2/25]: Iter 47, Loss 1.2955, Runtime 3m 42s\n",
      "Epoch [2/25]: Iter 48, Loss 1.3111, Runtime 3m 43s\n",
      "Epoch [2/25]: Iter 49, Loss 1.3501, Runtime 3m 44s\n",
      "Epoch [2/25]: Iter 50, Loss 1.2876, Runtime 3m 45s\n",
      "Epoch [2/25]: Iter 51, Loss 1.2955, Runtime 3m 46s\n",
      "Epoch [2/25]: Iter 52, Loss 1.2642, Runtime 3m 47s\n",
      "Epoch [2/25]: Iter 53, Loss 1.2564, Runtime 3m 48s\n",
      "Epoch [2/25]: Iter 54, Loss 1.2408, Runtime 3m 50s\n",
      "Epoch [2/25]: Iter 55, Loss 1.2330, Runtime 3m 51s\n",
      "Epoch [2/25]: Iter 56, Loss 1.3111, Runtime 3m 52s\n",
      "Epoch [2/25]: Iter 57, Loss 1.2330, Runtime 3m 53s\n",
      "Epoch [2/25]: Iter 58, Loss 1.2955, Runtime 3m 54s\n",
      "Epoch [2/25]: Iter 59, Loss 1.2798, Runtime 3m 55s\n",
      "Epoch [2/25]: Iter 60, Loss 1.2017, Runtime 3m 56s\n",
      "Epoch [2/25]: Iter 61, Loss 1.3189, Runtime 3m 57s\n",
      "Epoch [2/25]: Iter 62, Loss 1.3111, Runtime 3m 59s\n",
      "Epoch [2/25]: Iter 63, Loss 1.2564, Runtime 3m 60s\n",
      "Epoch [2/25]: Iter 64, Loss 1.2017, Runtime 4m 1s\n",
      "Epoch [2/25]: Iter 65, Loss 1.3267, Runtime 4m 2s\n",
      "Epoch [2/25]: Iter 66, Loss 1.2564, Runtime 4m 3s\n",
      "Epoch [2/25]: Iter 67, Loss 1.2798, Runtime 4m 4s\n",
      "Epoch [2/25]: Iter 68, Loss 1.2408, Runtime 4m 5s\n",
      "Epoch [2/25]: Iter 69, Loss 1.2642, Runtime 4m 6s\n",
      "Epoch [2/25]: Iter 70, Loss 1.2798, Runtime 4m 8s\n",
      "Epoch [2/25]: Iter 71, Loss 1.2408, Runtime 4m 9s\n",
      "Epoch [2/25]: Iter 72, Loss 1.2720, Runtime 4m 10s\n",
      "Epoch [2/25]: Iter 73, Loss 1.2564, Runtime 4m 11s\n",
      "Epoch [2/25]: Iter 74, Loss 1.3814, Runtime 4m 12s\n",
      "Epoch [2/25]: Iter 75, Loss 1.2564, Runtime 4m 13s\n",
      "Epoch [2/25]: Iter 76, Loss 1.2642, Runtime 4m 14s\n",
      "Epoch [2/25]: Iter 77, Loss 1.3736, Runtime 4m 15s\n",
      "Epoch [2/25]: Iter 78, Loss 1.2486, Runtime 4m 17s\n",
      "Epoch [2/25]: Iter 79, Loss 1.3033, Runtime 4m 18s\n",
      "Epoch [2/25]: Iter 80, Loss 1.2876, Runtime 4m 19s\n",
      "Epoch [2/25]: Iter 81, Loss 1.2251, Runtime 4m 20s\n",
      "Epoch [2/25]: Iter 82, Loss 1.3501, Runtime 4m 21s\n",
      "Epoch [2/25]: Iter 83, Loss 1.2095, Runtime 4m 22s\n",
      "Epoch [2/25]: Iter 84, Loss 1.3580, Runtime 4m 23s\n",
      "Epoch [2/25]: Iter 85, Loss 1.3580, Runtime 4m 24s\n",
      "Epoch [2/25]: Iter 86, Loss 1.2330, Runtime 4m 26s\n",
      "Epoch [2/25]: Iter 87, Loss 1.3970, Runtime 4m 27s\n",
      "Epoch [2/25]: Iter 88, Loss 1.3267, Runtime 4m 28s\n",
      "Epoch [2/25]: Iter 89, Loss 1.3033, Runtime 4m 29s\n",
      "Epoch [2/25]: Iter 90, Loss 1.2955, Runtime 4m 30s\n",
      "Epoch [2/25]: Iter 91, Loss 1.2330, Runtime 4m 31s\n",
      "Epoch [2/25]: Iter 92, Loss 1.3423, Runtime 4m 32s\n",
      "Epoch [2/25]: Iter 93, Loss 1.3580, Runtime 4m 34s\n",
      "Epoch [2/25]: Iter 94, Loss 1.3580, Runtime 4m 35s\n",
      "Epoch [2/25]: Iter 95, Loss 1.3423, Runtime 4m 36s\n",
      "Epoch [2/25]: Iter 96, Loss 1.3892, Runtime 4m 37s\n",
      "Epoch [2/25]: Iter 97, Loss 1.2955, Runtime 4m 38s\n",
      "Epoch [2/25]: Iter 98, Loss 1.3423, Runtime 4m 39s\n",
      "Epoch [2/25]: Iter 99, Loss 1.1783, Runtime 4m 40s\n",
      "Epoch [2/25]: Iter 100, Loss 1.3423, Runtime 4m 41s\n",
      "Epoch [2/25]: Iter 101, Loss 1.3189, Runtime 4m 43s\n",
      "Epoch [2/25]: Iter 102, Loss 1.1861, Runtime 4m 44s\n",
      "Epoch [2/25]: Iter 103, Loss 1.2095, Runtime 4m 45s\n",
      "Epoch [2/25]: Iter 104, Loss 1.3111, Runtime 4m 46s\n",
      "Epoch [2/25]: Iter 105, Loss 1.3501, Runtime 4m 47s\n",
      "Epoch [2/25]: Iter 106, Loss 1.2720, Runtime 4m 48s\n",
      "Epoch [2/25]: Iter 107, Loss 1.2876, Runtime 4m 49s\n",
      "Epoch [2/25]: Iter 108, Loss 1.2408, Runtime 4m 50s\n",
      "Epoch [2/25]: Iter 109, Loss 1.3345, Runtime 4m 52s\n",
      "Epoch [2/25]: Iter 110, Loss 1.3189, Runtime 4m 53s\n",
      "Epoch [2/25]: Iter 111, Loss 1.2720, Runtime 4m 54s\n",
      "Epoch [2/25]: Iter 112, Loss 1.3111, Runtime 4m 55s\n",
      "Epoch [2/25]: Iter 113, Loss 1.3345, Runtime 4m 56s\n",
      "Epoch [2/25]: Iter 114, Loss 1.3033, Runtime 4m 57s\n",
      "Epoch [2/25]: Iter 115, Loss 1.2798, Runtime 4m 58s\n",
      "Epoch [2/25]: Iter 116, Loss 1.3033, Runtime 4m 59s\n",
      "Epoch [2/25]: Iter 117, Loss 1.3189, Runtime 5m 1s\n",
      "Epoch [2/25]: Iter 118, Loss 1.3632, Runtime 5m 1s\n",
      "Testing on test dataset...\n",
      "Epoch [2/25] Loss: 152.4394 Train_Acc: 61.3467  Test_Acc: 61.8415\n",
      "Epoch [3/25]: Iter 1, Loss 1.2251, Runtime 5m 36s\n",
      "Epoch [3/25]: Iter 2, Loss 1.2095, Runtime 5m 37s\n",
      "Epoch [3/25]: Iter 3, Loss 1.2486, Runtime 5m 38s\n",
      "Epoch [3/25]: Iter 4, Loss 1.3580, Runtime 5m 39s\n",
      "Epoch [3/25]: Iter 5, Loss 1.3658, Runtime 5m 41s\n",
      "Epoch [3/25]: Iter 6, Loss 1.3033, Runtime 5m 42s\n",
      "Epoch [3/25]: Iter 7, Loss 1.2720, Runtime 5m 43s\n",
      "Epoch [3/25]: Iter 8, Loss 1.2486, Runtime 5m 44s\n",
      "Epoch [3/25]: Iter 9, Loss 1.2955, Runtime 5m 45s\n",
      "Epoch [3/25]: Iter 10, Loss 1.2798, Runtime 5m 46s\n",
      "Epoch [3/25]: Iter 11, Loss 1.3423, Runtime 5m 47s\n",
      "Epoch [3/25]: Iter 12, Loss 1.2408, Runtime 5m 49s\n",
      "Epoch [3/25]: Iter 13, Loss 1.3267, Runtime 5m 50s\n",
      "Epoch [3/25]: Iter 14, Loss 1.3111, Runtime 5m 51s\n",
      "Epoch [3/25]: Iter 15, Loss 1.3189, Runtime 5m 52s\n",
      "Epoch [3/25]: Iter 16, Loss 1.3033, Runtime 5m 53s\n",
      "Epoch [3/25]: Iter 17, Loss 1.2720, Runtime 5m 54s\n",
      "Epoch [3/25]: Iter 18, Loss 1.2876, Runtime 5m 55s\n",
      "Epoch [3/25]: Iter 19, Loss 1.3111, Runtime 5m 56s\n",
      "Epoch [3/25]: Iter 20, Loss 1.3189, Runtime 5m 58s\n",
      "Epoch [3/25]: Iter 21, Loss 1.2486, Runtime 5m 59s\n",
      "Epoch [3/25]: Iter 22, Loss 1.3423, Runtime 5m 60s\n",
      "Epoch [3/25]: Iter 23, Loss 1.3033, Runtime 6m 1s\n",
      "Epoch [3/25]: Iter 24, Loss 1.2564, Runtime 6m 2s\n",
      "Epoch [3/25]: Iter 25, Loss 1.3189, Runtime 6m 3s\n",
      "Epoch [3/25]: Iter 26, Loss 1.3189, Runtime 6m 4s\n",
      "Epoch [3/25]: Iter 27, Loss 1.3267, Runtime 6m 5s\n",
      "Epoch [3/25]: Iter 28, Loss 1.3189, Runtime 6m 7s\n",
      "Epoch [3/25]: Iter 29, Loss 1.2251, Runtime 6m 8s\n",
      "Epoch [3/25]: Iter 30, Loss 1.2720, Runtime 6m 9s\n",
      "Epoch [3/25]: Iter 31, Loss 1.2564, Runtime 6m 10s\n",
      "Epoch [3/25]: Iter 32, Loss 1.3111, Runtime 6m 11s\n",
      "Epoch [3/25]: Iter 33, Loss 1.2955, Runtime 6m 12s\n",
      "Epoch [3/25]: Iter 34, Loss 1.2955, Runtime 6m 13s\n",
      "Epoch [3/25]: Iter 35, Loss 1.2330, Runtime 6m 14s\n",
      "Epoch [3/25]: Iter 36, Loss 1.3189, Runtime 6m 16s\n",
      "Epoch [3/25]: Iter 37, Loss 1.2408, Runtime 6m 17s\n",
      "Epoch [3/25]: Iter 38, Loss 1.2486, Runtime 6m 18s\n",
      "Epoch [3/25]: Iter 39, Loss 1.2564, Runtime 6m 19s\n",
      "Epoch [3/25]: Iter 40, Loss 1.3501, Runtime 6m 20s\n",
      "Epoch [3/25]: Iter 41, Loss 1.3423, Runtime 6m 21s\n",
      "Epoch [3/25]: Iter 42, Loss 1.3345, Runtime 6m 22s\n",
      "Epoch [3/25]: Iter 43, Loss 1.2564, Runtime 6m 23s\n",
      "Epoch [3/25]: Iter 44, Loss 1.2408, Runtime 6m 25s\n",
      "Epoch [3/25]: Iter 45, Loss 1.3267, Runtime 6m 26s\n",
      "Epoch [3/25]: Iter 46, Loss 1.2876, Runtime 6m 27s\n",
      "Epoch [3/25]: Iter 47, Loss 1.3345, Runtime 6m 28s\n",
      "Epoch [3/25]: Iter 48, Loss 1.2486, Runtime 6m 29s\n",
      "Epoch [3/25]: Iter 49, Loss 1.1783, Runtime 6m 30s\n",
      "Epoch [3/25]: Iter 50, Loss 1.2876, Runtime 6m 31s\n",
      "Epoch [3/25]: Iter 51, Loss 1.2408, Runtime 6m 32s\n",
      "Epoch [3/25]: Iter 52, Loss 1.3970, Runtime 6m 34s\n",
      "Epoch [3/25]: Iter 53, Loss 1.3111, Runtime 6m 35s\n",
      "Epoch [3/25]: Iter 54, Loss 1.2720, Runtime 6m 36s\n",
      "Epoch [3/25]: Iter 55, Loss 1.2564, Runtime 6m 37s\n",
      "Epoch [3/25]: Iter 56, Loss 1.3111, Runtime 6m 38s\n",
      "Epoch [3/25]: Iter 57, Loss 1.2251, Runtime 6m 39s\n",
      "Epoch [3/25]: Iter 58, Loss 1.2486, Runtime 6m 40s\n",
      "Epoch [3/25]: Iter 59, Loss 1.3501, Runtime 6m 42s\n",
      "Epoch [3/25]: Iter 60, Loss 1.2955, Runtime 6m 43s\n",
      "Epoch [3/25]: Iter 61, Loss 1.2955, Runtime 6m 44s\n",
      "Epoch [3/25]: Iter 62, Loss 1.2876, Runtime 6m 45s\n",
      "Epoch [3/25]: Iter 63, Loss 1.2642, Runtime 6m 46s\n",
      "Epoch [3/25]: Iter 64, Loss 1.3658, Runtime 6m 47s\n",
      "Epoch [3/25]: Iter 65, Loss 1.2720, Runtime 6m 48s\n",
      "Epoch [3/25]: Iter 66, Loss 1.3345, Runtime 6m 49s\n",
      "Epoch [3/25]: Iter 67, Loss 1.3658, Runtime 6m 51s\n",
      "Epoch [3/25]: Iter 68, Loss 1.2251, Runtime 6m 52s\n",
      "Epoch [3/25]: Iter 69, Loss 1.3580, Runtime 6m 53s\n",
      "Epoch [3/25]: Iter 70, Loss 1.2955, Runtime 6m 54s\n",
      "Epoch [3/25]: Iter 71, Loss 1.2642, Runtime 6m 55s\n",
      "Epoch [3/25]: Iter 72, Loss 1.3658, Runtime 6m 56s\n",
      "Epoch [3/25]: Iter 73, Loss 1.3501, Runtime 6m 57s\n",
      "Epoch [3/25]: Iter 74, Loss 1.3033, Runtime 6m 58s\n",
      "Epoch [3/25]: Iter 75, Loss 1.2408, Runtime 6m 60s\n",
      "Epoch [3/25]: Iter 76, Loss 1.3658, Runtime 7m 1s\n",
      "Epoch [3/25]: Iter 77, Loss 1.2564, Runtime 7m 2s\n",
      "Epoch [3/25]: Iter 78, Loss 1.3658, Runtime 7m 3s\n",
      "Epoch [3/25]: Iter 79, Loss 1.2408, Runtime 7m 4s\n",
      "Epoch [3/25]: Iter 80, Loss 1.2876, Runtime 7m 5s\n",
      "Epoch [3/25]: Iter 81, Loss 1.3033, Runtime 7m 6s\n",
      "Epoch [3/25]: Iter 82, Loss 1.1861, Runtime 7m 7s\n",
      "Epoch [3/25]: Iter 83, Loss 1.2720, Runtime 7m 9s\n",
      "Epoch [3/25]: Iter 84, Loss 1.2955, Runtime 7m 10s\n",
      "Epoch [3/25]: Iter 85, Loss 1.3111, Runtime 7m 11s\n",
      "Epoch [3/25]: Iter 86, Loss 1.2330, Runtime 7m 12s\n",
      "Epoch [3/25]: Iter 87, Loss 1.3501, Runtime 7m 13s\n",
      "Epoch [3/25]: Iter 88, Loss 1.2955, Runtime 7m 14s\n",
      "Epoch [3/25]: Iter 89, Loss 1.2408, Runtime 7m 15s\n",
      "Epoch [3/25]: Iter 90, Loss 1.2955, Runtime 7m 16s\n",
      "Epoch [3/25]: Iter 91, Loss 1.3111, Runtime 7m 18s\n",
      "Epoch [3/25]: Iter 92, Loss 1.3111, Runtime 7m 19s\n",
      "Epoch [3/25]: Iter 93, Loss 1.3423, Runtime 7m 20s\n",
      "Epoch [3/25]: Iter 94, Loss 1.2330, Runtime 7m 21s\n",
      "Epoch [3/25]: Iter 95, Loss 1.2798, Runtime 7m 22s\n",
      "Epoch [3/25]: Iter 96, Loss 1.2251, Runtime 7m 23s\n",
      "Epoch [3/25]: Iter 97, Loss 1.3423, Runtime 7m 24s\n",
      "Epoch [3/25]: Iter 98, Loss 1.3658, Runtime 7m 25s\n",
      "Epoch [3/25]: Iter 99, Loss 1.2955, Runtime 7m 27s\n",
      "Epoch [3/25]: Iter 100, Loss 1.2095, Runtime 7m 28s\n",
      "Epoch [3/25]: Iter 101, Loss 1.2955, Runtime 7m 29s\n",
      "Epoch [3/25]: Iter 102, Loss 1.3189, Runtime 7m 30s\n",
      "Epoch [3/25]: Iter 103, Loss 1.3423, Runtime 7m 31s\n",
      "Epoch [3/25]: Iter 104, Loss 1.3033, Runtime 7m 32s\n",
      "Epoch [3/25]: Iter 105, Loss 1.3033, Runtime 7m 33s\n",
      "Epoch [3/25]: Iter 106, Loss 1.3345, Runtime 7m 35s\n",
      "Epoch [3/25]: Iter 107, Loss 1.3345, Runtime 7m 36s\n",
      "Epoch [3/25]: Iter 108, Loss 1.2017, Runtime 7m 37s\n",
      "Epoch [3/25]: Iter 109, Loss 1.2798, Runtime 7m 38s\n",
      "Epoch [3/25]: Iter 110, Loss 1.2173, Runtime 7m 39s\n",
      "Epoch [3/25]: Iter 111, Loss 1.3501, Runtime 7m 40s\n",
      "Epoch [3/25]: Iter 112, Loss 1.2017, Runtime 7m 41s\n",
      "Epoch [3/25]: Iter 113, Loss 1.2876, Runtime 7m 42s\n",
      "Epoch [3/25]: Iter 114, Loss 1.3423, Runtime 7m 44s\n",
      "Epoch [3/25]: Iter 115, Loss 1.2798, Runtime 7m 45s\n",
      "Epoch [3/25]: Iter 116, Loss 1.2798, Runtime 7m 46s\n",
      "Epoch [3/25]: Iter 117, Loss 1.2564, Runtime 7m 47s\n",
      "Epoch [3/25]: Iter 118, Loss 1.4882, Runtime 7m 47s\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7813/1907990333.py\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Testing on test dataset...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     print('Epoch [{}/{}] Loss: {:.4f} Train_Acc: {:.4f}  Test_Acc: {:.4f}'\n\u001b[1;32m     45\u001b[0m           .format(epoch + 1, num_epochs, epoch_loss, train_acc, test_acc))\n",
      "\u001b[0;32m/tmp/ipykernel_7813/4190752226.py\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(model, test_loader)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/prefetch_generator/__init__.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mContinue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_item\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mnext_item\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_acc = 0.\n",
    "best_epoch = None\n",
    "end_patient = 0\n",
    "num_epochs = 25\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=3, verbose=True)\n",
    "\n",
    "save_model_path = ''\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "#model = torch.compile(model)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    epoch_loss = 0.\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        correct += (prediction == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        time_diff = get_run_time(start_time)\n",
    "\n",
    "        print('Epoch [{}/{}]: Iter {}, Loss {:.4f}, Runtime {:.0f}m {:.0f}s'.format(epoch + 1, num_epochs, i + 1, loss, time_diff//60, time_diff%60))\n",
    "        train_loss.append(loss)\n",
    "    \n",
    "    train_acc = 100 * correct / total\n",
    "    print('Testing on test dataset...')\n",
    "    test_acc = test_model(model, test_loader)\n",
    "    print('Epoch [{}/{}] Loss: {:.4f} Train_Acc: {:.4f}  Test_Acc: {:.4f}'\n",
    "          .format(epoch + 1, num_epochs, epoch_loss, train_acc, test_acc))\n",
    "    scheduler.step(test_acc)\n",
    "    train_accuracy.append(train_acc)\n",
    "    test_accuracy.append(test_acc)\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        best_epoch = epoch + 1\n",
    "        print('The accuracy is improved, save model')\n",
    "        torch.save(model.state_dict(), os.path.join(\n",
    "                                                    'resnet34_tuning_epoch_%d_acc_%g.pth' %\n",
    "                                                    (best_epoch, best_acc)))\n",
    "\n",
    "print('After the training, the end of the epoch %d, the accuracy %g is the highest' % (best_epoch, best_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1,51),train_accuracy,label='Train Accuracy')\n",
    "plt.plot(np.arange(1,51),test_accuracy,label='Test Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Versus Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = OurModel(5).to(device)\n",
    "model.load_state_dict(torch.load('resnet34_tuning_epoch_29_acc_83.689.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nb_classes = 5\n",
    "\n",
    "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(test_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=True,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm/ np.sum(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2%' #if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "num_classes=5\n",
    "M = confusion_matrix.numpy()\n",
    "plot_confusion_matrix(M, classes=np.arange(num_classes), normalize=True)\n",
    "print(\"Accuracy:\",np.trace(M/np.sum(M)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
