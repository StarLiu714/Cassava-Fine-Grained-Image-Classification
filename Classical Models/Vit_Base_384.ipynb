{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Apr 25 19:13:52 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A10G         On   | 00000000:00:1E.0 Off |                    0 |\n",
      "|  0%   35C    P8    37W / 300W |      0MiB / 23028MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: prefetch_generator in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (1.0.3)\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: timm in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (0.6.13)\n",
      "Requirement already satisfied: huggingface-hub in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from timm) (0.14.1)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from timm) (0.14.1)\n",
      "Requirement already satisfied: torch>=1.7 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from timm) (1.13.1)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from timm) (5.4.1)\n",
      "Requirement already satisfied: typing_extensions in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from torch>=1.7->timm) (4.4.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface-hub->timm) (4.63.2)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface-hub->timm) (2022.11.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface-hub->timm) (3.6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface-hub->timm) (21.3)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from huggingface-hub->timm) (2.28.1)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from torchvision->timm) (1.23.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from torchvision->timm) (9.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from packaging>=20.9->huggingface-hub->timm) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->huggingface-hub->timm) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->huggingface-hub->timm) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->huggingface-hub->timm) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from requests->huggingface-hub->timm) (1.26.8)\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: albumentations in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (1.3.0)\n",
      "Requirement already satisfied: PyYAML in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from albumentations) (5.4.1)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from albumentations) (1.8.1)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from albumentations) (1.23.5)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from albumentations) (0.19.3)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from albumentations) (4.7.0.72)\n",
      "Requirement already satisfied: qudida>=0.0.4 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from albumentations) (0.0.4)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from qudida>=0.0.4->albumentations) (4.4.0)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from qudida>=0.0.4->albumentations) (1.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (1.4.1)\n",
      "Requirement already satisfied: networkx>=2.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (3.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (2022.10.10)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (9.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (21.3)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from scikit-image>=0.16.1->albumentations) (2.16.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from packaging>=20.0->scikit-image>=0.16.1->albumentations) (3.0.9)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "!pip install prefetch_generator\n",
    "!pip install timm\n",
    "!pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "import torchvision\n",
    "import boto3\n",
    "import io\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import tempfile\n",
    "import PIL\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from prefetch_generator import BackgroundGenerator\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from sklearn import model_selection, metrics\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're using: cuda\n"
     ]
    }
   ],
   "source": [
    "# Make sure you're using cuda (GPU) by checking the hardware accelerator under Runtime -> Change runtime type\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"We're using:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.image_path = 'Dataset/train_images'\n",
    "        self.labels = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        img_name = self.image_path + '/' + self.labels.iloc[idx]['image_id']\n",
    "\n",
    "        # Read the image from the file path\n",
    "        image = cv2.imread(img_name)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Transform the image using self.transform\n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "\n",
    "        if \"label\" in self.labels.columns:\n",
    "            label = self.labels.iloc[idx]['label']\n",
    "            sample = (image, label)\n",
    "        else:\n",
    "            sample = (image)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transforms_train = A.Compose(\n",
    "    [\n",
    "        A.Resize(384, 384),\n",
    "        A.HorizontalFlip(p=0.3),\n",
    "        A.VerticalFlip(p=0.3),\n",
    "        A.RandomResizedCrop(384, 384),\n",
    "        A.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "        ToTensorV2()\n",
    "    ]\n",
    ")\n",
    "\n",
    "transforms_test = A.Compose(\n",
    "    [\n",
    "        A.Resize(384, 384),\n",
    "        A.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Dataset/train.csv')\n",
    "\n",
    "train_df, test_df = model_selection.train_test_split(\n",
    "    df, test_size=0.3, random_state=42, stratify=df.label.values\n",
    ")\n",
    "\n",
    "train_data = MyDataset(train_df, transform = transforms_train)\n",
    "test_data = MyDataset(test_df, transform = transforms_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['convit_base',\n",
       " 'convit_small',\n",
       " 'convit_tiny',\n",
       " 'crossvit_9_240',\n",
       " 'crossvit_9_dagger_240',\n",
       " 'crossvit_15_240',\n",
       " 'crossvit_15_dagger_240',\n",
       " 'crossvit_15_dagger_408',\n",
       " 'crossvit_18_240',\n",
       " 'crossvit_18_dagger_240',\n",
       " 'crossvit_18_dagger_408',\n",
       " 'crossvit_base_240',\n",
       " 'crossvit_small_240',\n",
       " 'crossvit_tiny_240',\n",
       " 'gcvit_base',\n",
       " 'gcvit_small',\n",
       " 'gcvit_tiny',\n",
       " 'gcvit_xtiny',\n",
       " 'gcvit_xxtiny',\n",
       " 'levit_128',\n",
       " 'levit_128s',\n",
       " 'levit_192',\n",
       " 'levit_256',\n",
       " 'levit_256d',\n",
       " 'levit_384',\n",
       " 'maxvit_base_224',\n",
       " 'maxvit_large_224',\n",
       " 'maxvit_nano_rw_256',\n",
       " 'maxvit_pico_rw_256',\n",
       " 'maxvit_rmlp_nano_rw_256',\n",
       " 'maxvit_rmlp_pico_rw_256',\n",
       " 'maxvit_rmlp_small_rw_224',\n",
       " 'maxvit_rmlp_small_rw_256',\n",
       " 'maxvit_rmlp_tiny_rw_256',\n",
       " 'maxvit_small_224',\n",
       " 'maxvit_tiny_224',\n",
       " 'maxvit_tiny_pm_256',\n",
       " 'maxvit_tiny_rw_224',\n",
       " 'maxvit_tiny_rw_256',\n",
       " 'maxvit_xlarge_224',\n",
       " 'maxxvit_rmlp_nano_rw_256',\n",
       " 'maxxvit_rmlp_small_rw_256',\n",
       " 'maxxvit_rmlp_tiny_rw_256',\n",
       " 'mobilevit_s',\n",
       " 'mobilevit_xs',\n",
       " 'mobilevit_xxs',\n",
       " 'mobilevitv2_050',\n",
       " 'mobilevitv2_075',\n",
       " 'mobilevitv2_100',\n",
       " 'mobilevitv2_125',\n",
       " 'mobilevitv2_150',\n",
       " 'mobilevitv2_150_384_in22ft1k',\n",
       " 'mobilevitv2_150_in22ft1k',\n",
       " 'mobilevitv2_175',\n",
       " 'mobilevitv2_175_384_in22ft1k',\n",
       " 'mobilevitv2_175_in22ft1k',\n",
       " 'mobilevitv2_200',\n",
       " 'mobilevitv2_200_384_in22ft1k',\n",
       " 'mobilevitv2_200_in22ft1k',\n",
       " 'mvitv2_base',\n",
       " 'mvitv2_large',\n",
       " 'mvitv2_small',\n",
       " 'mvitv2_small_cls',\n",
       " 'mvitv2_tiny',\n",
       " 'semobilevit_s',\n",
       " 'vit_base_patch8_224',\n",
       " 'vit_base_patch8_224_dino',\n",
       " 'vit_base_patch8_224_in21k',\n",
       " 'vit_base_patch16_18x2_224',\n",
       " 'vit_base_patch16_224',\n",
       " 'vit_base_patch16_224_dino',\n",
       " 'vit_base_patch16_224_in21k',\n",
       " 'vit_base_patch16_224_miil',\n",
       " 'vit_base_patch16_224_miil_in21k',\n",
       " 'vit_base_patch16_224_sam',\n",
       " 'vit_base_patch16_384',\n",
       " 'vit_base_patch16_plus_240',\n",
       " 'vit_base_patch16_rpn_224',\n",
       " 'vit_base_patch32_224',\n",
       " 'vit_base_patch32_224_clip_laion2b',\n",
       " 'vit_base_patch32_224_in21k',\n",
       " 'vit_base_patch32_224_sam',\n",
       " 'vit_base_patch32_384',\n",
       " 'vit_base_patch32_plus_256',\n",
       " 'vit_base_r26_s32_224',\n",
       " 'vit_base_r50_s16_224',\n",
       " 'vit_base_r50_s16_224_in21k',\n",
       " 'vit_base_r50_s16_384',\n",
       " 'vit_base_resnet26d_224',\n",
       " 'vit_base_resnet50_224_in21k',\n",
       " 'vit_base_resnet50_384',\n",
       " 'vit_base_resnet50d_224',\n",
       " 'vit_giant_patch14_224',\n",
       " 'vit_giant_patch14_224_clip_laion2b',\n",
       " 'vit_gigantic_patch14_224',\n",
       " 'vit_huge_patch14_224',\n",
       " 'vit_huge_patch14_224_clip_laion2b',\n",
       " 'vit_huge_patch14_224_in21k',\n",
       " 'vit_large_patch14_224',\n",
       " 'vit_large_patch14_224_clip_laion2b',\n",
       " 'vit_large_patch16_224',\n",
       " 'vit_large_patch16_224_in21k',\n",
       " 'vit_large_patch16_384',\n",
       " 'vit_large_patch32_224',\n",
       " 'vit_large_patch32_224_in21k',\n",
       " 'vit_large_patch32_384',\n",
       " 'vit_large_r50_s32_224',\n",
       " 'vit_large_r50_s32_224_in21k',\n",
       " 'vit_large_r50_s32_384',\n",
       " 'vit_relpos_base_patch16_224',\n",
       " 'vit_relpos_base_patch16_cls_224',\n",
       " 'vit_relpos_base_patch16_clsgap_224',\n",
       " 'vit_relpos_base_patch16_plus_240',\n",
       " 'vit_relpos_base_patch16_rpn_224',\n",
       " 'vit_relpos_base_patch32_plus_rpn_256',\n",
       " 'vit_relpos_medium_patch16_224',\n",
       " 'vit_relpos_medium_patch16_cls_224',\n",
       " 'vit_relpos_medium_patch16_rpn_224',\n",
       " 'vit_relpos_small_patch16_224',\n",
       " 'vit_relpos_small_patch16_rpn_224',\n",
       " 'vit_small_patch8_224_dino',\n",
       " 'vit_small_patch16_18x2_224',\n",
       " 'vit_small_patch16_36x1_224',\n",
       " 'vit_small_patch16_224',\n",
       " 'vit_small_patch16_224_dino',\n",
       " 'vit_small_patch16_224_in21k',\n",
       " 'vit_small_patch16_384',\n",
       " 'vit_small_patch32_224',\n",
       " 'vit_small_patch32_224_in21k',\n",
       " 'vit_small_patch32_384',\n",
       " 'vit_small_r26_s32_224',\n",
       " 'vit_small_r26_s32_224_in21k',\n",
       " 'vit_small_r26_s32_384',\n",
       " 'vit_small_resnet26d_224',\n",
       " 'vit_small_resnet50d_s16_224',\n",
       " 'vit_srelpos_medium_patch16_224',\n",
       " 'vit_srelpos_small_patch16_224',\n",
       " 'vit_tiny_patch16_224',\n",
       " 'vit_tiny_patch16_224_in21k',\n",
       " 'vit_tiny_patch16_384',\n",
       " 'vit_tiny_r_s16_p8_224',\n",
       " 'vit_tiny_r_s16_p8_224_in21k',\n",
       " 'vit_tiny_r_s16_p8_384']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.list_models('*vit*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'https://storage.googleapis.com/vit_models/augreg/B_16-i21k-300ep-lr_0.001-aug_medium1-wd_0.1-do_0.0-sd_0.0--imagenet2012-steps_20k-lr_0.01-res_384.npz',\n",
       " 'num_classes': 1000,\n",
       " 'input_size': (3, 384, 384),\n",
       " 'pool_size': None,\n",
       " 'crop_pct': 1.0,\n",
       " 'interpolation': 'bicubic',\n",
       " 'fixed_input_size': True,\n",
       " 'mean': (0.5, 0.5, 0.5),\n",
       " 'std': (0.5, 0.5, 0.5),\n",
       " 'first_conv': 'patch_embed.proj',\n",
       " 'classifier': 'head',\n",
       " 'architecture': 'vit_base_patch16_384'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model = timm.create_model('vit_base_patch16_384', pretrained=True)\n",
    "test_model.default_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class OurModel(nn.Module):\n",
    "  def __init__(self, num_classes):\n",
    "    super(OurModel, self).__init__()\n",
    "    self.model = timm.create_model('vit_base_patch16_384', pretrained=True)\n",
    "    self.model.head = nn.Linear(self.model.head.in_features, num_classes)\n",
    "\n",
    "  def forward(self, input):\n",
    "    out = self.model(input)\n",
    "    return out #F.softmax(out, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# Label Smoothing\n",
    "# ====================================================\n",
    "class LabelSmoothingLoss(nn.Module): \n",
    "    def __init__(self, classes=5, smoothing=0.0, dim=-1): \n",
    "        super(LabelSmoothingLoss, self).__init__() \n",
    "        self.confidence = 1.0 - smoothing \n",
    "        self.smoothing = smoothing \n",
    "        self.cls = classes \n",
    "        self.dim = dim \n",
    "    def forward(self, pred, target): \n",
    "        pred = pred.log_softmax(dim=self.dim) \n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred) \n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1)) \n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence) \n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = nn.CrossEntropyLoss()(inputs, targets)\n",
    "\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalCosineLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, xent=.1):\n",
    "        super(FocalCosineLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "        self.xent = xent\n",
    "\n",
    "        self.y = torch.Tensor([1]).cuda()\n",
    "\n",
    "    def forward(self, input, target, reduction=\"mean\"):\n",
    "        cosine_loss = F.cosine_embedding_loss(input, F.one_hot(target, num_classes=input.size(-1)), self.y, reduction=reduction)\n",
    "\n",
    "        cent_loss = F.cross_entropy(F.normalize(input), target, reduce=False)\n",
    "        pt = torch.exp(-cent_loss)\n",
    "        focal_loss = self.alpha * (1-pt)**self.gamma * cent_loss\n",
    "\n",
    "        if reduction == \"mean\":\n",
    "            focal_loss = torch.mean(focal_loss)\n",
    "\n",
    "        return cosine_loss + self.xent * focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SymmetricCrossEntropy(nn.Module):\n",
    "\n",
    "    def __init__(self, alpha=0.1, beta=1.0, num_classes=5):\n",
    "        super(SymmetricCrossEntropy, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, logits, targets, reduction='mean'):\n",
    "        onehot_targets = torch.eye(self.num_classes)[targets].cuda()\n",
    "        ce_loss = F.cross_entropy(logits, targets, reduction=reduction)\n",
    "        rce_loss = (-onehot_targets*logits.softmax(1).clamp(1e-7, 1.0).log()).sum(1)\n",
    "        if reduction == 'mean':\n",
    "            rce_loss = rce_loss.mean()\n",
    "        elif reduction == 'sum':\n",
    "            rce_loss = rce_loss.sum()\n",
    "        return self.alpha * ce_loss + self.beta * rce_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_t(u, t):\n",
    "    \"\"\"Compute log_t for `u'.\"\"\"\n",
    "    if t==1.0:\n",
    "        return u.log()\n",
    "    else:\n",
    "        return (u.pow(1.0 - t) - 1.0) / (1.0 - t)\n",
    "\n",
    "def exp_t(u, t):\n",
    "    \"\"\"Compute exp_t for `u'.\"\"\"\n",
    "    if t==1:\n",
    "        return u.exp()\n",
    "    else:\n",
    "        return (1.0 + (1.0-t)*u).relu().pow(1.0 / (1.0 - t))\n",
    "\n",
    "def compute_normalization_fixed_point(activations, t, num_iters):\n",
    "\n",
    "    \"\"\"Returns the normalization value for each example (t > 1.0).\n",
    "    Args:\n",
    "      activations: A multi-dimensional tensor with last dimension `num_classes`.\n",
    "      t: Temperature 2 (> 1.0 for tail heaviness).\n",
    "      num_iters: Number of iterations to run the method.\n",
    "    Return: A tensor of same shape as activation with the last dimension being 1.\n",
    "    \"\"\"\n",
    "    mu, _ = torch.max(activations, -1, keepdim=True)\n",
    "    normalized_activations_step_0 = activations - mu\n",
    "\n",
    "    normalized_activations = normalized_activations_step_0\n",
    "\n",
    "    for _ in range(num_iters):\n",
    "        logt_partition = torch.sum(\n",
    "                exp_t(normalized_activations, t), -1, keepdim=True)\n",
    "        normalized_activations = normalized_activations_step_0 * \\\n",
    "                logt_partition.pow(1.0-t)\n",
    "\n",
    "    logt_partition = torch.sum(\n",
    "            exp_t(normalized_activations, t), -1, keepdim=True)\n",
    "    normalization_constants = - log_t(1.0 / logt_partition, t) + mu\n",
    "\n",
    "    return normalization_constants\n",
    "\n",
    "def compute_normalization_binary_search(activations, t, num_iters):\n",
    "\n",
    "    \"\"\"Returns the normalization value for each example (t < 1.0).\n",
    "    Args:\n",
    "      activations: A multi-dimensional tensor with last dimension `num_classes`.\n",
    "      t: Temperature 2 (< 1.0 for finite support).\n",
    "      num_iters: Number of iterations to run the method.\n",
    "    Return: A tensor of same rank as activation with the last dimension being 1.\n",
    "    \"\"\"\n",
    "\n",
    "    mu, _ = torch.max(activations, -1, keepdim=True)\n",
    "    normalized_activations = activations - mu\n",
    "\n",
    "    effective_dim = \\\n",
    "        torch.sum(\n",
    "                (normalized_activations > -1.0 / (1.0-t)).to(torch.int32),\n",
    "            dim=-1, keepdim=True).to(activations.dtype)\n",
    "\n",
    "    shape_partition = activations.shape[:-1] + (1,)\n",
    "    lower = torch.zeros(shape_partition, dtype=activations.dtype, device=activations.device)\n",
    "    upper = -log_t(1.0/effective_dim, t) * torch.ones_like(lower)\n",
    "\n",
    "    for _ in range(num_iters):\n",
    "        logt_partition = (upper + lower)/2.0\n",
    "        sum_probs = torch.sum(\n",
    "                exp_t(normalized_activations - logt_partition, t),\n",
    "                dim=-1, keepdim=True)\n",
    "        update = (sum_probs < 1.0).to(activations.dtype)\n",
    "        lower = torch.reshape(\n",
    "                lower * update + (1.0-update) * logt_partition,\n",
    "                shape_partition)\n",
    "        upper = torch.reshape(\n",
    "                upper * (1.0 - update) + update * logt_partition,\n",
    "                shape_partition)\n",
    "\n",
    "    logt_partition = (upper + lower)/2.0\n",
    "    return logt_partition + mu\n",
    "\n",
    "class ComputeNormalization(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Class implementing custom backward pass for compute_normalization. See compute_normalization.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def forward(ctx, activations, t, num_iters):\n",
    "        if t < 1.0:\n",
    "            normalization_constants = compute_normalization_binary_search(activations, t, num_iters)\n",
    "        else:\n",
    "            normalization_constants = compute_normalization_fixed_point(activations, t, num_iters)\n",
    "\n",
    "        ctx.save_for_backward(activations, normalization_constants)\n",
    "        ctx.t=t\n",
    "        return normalization_constants\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        activations, normalization_constants = ctx.saved_tensors\n",
    "        t = ctx.t\n",
    "        normalized_activations = activations - normalization_constants \n",
    "        probabilities = exp_t(normalized_activations, t)\n",
    "        escorts = probabilities.pow(t)\n",
    "        escorts = escorts / escorts.sum(dim=-1, keepdim=True)\n",
    "        grad_input = escorts * grad_output\n",
    "        \n",
    "        return grad_input, None, None\n",
    "\n",
    "def compute_normalization(activations, t, num_iters=5):\n",
    "    \"\"\"Returns the normalization value for each example. \n",
    "    Backward pass is implemented.\n",
    "    Args:\n",
    "      activations: A multi-dimensional tensor with last dimension `num_classes`.\n",
    "      t: Temperature 2 (> 1.0 for tail heaviness, < 1.0 for finite support).\n",
    "      num_iters: Number of iterations to run the method.\n",
    "    Return: A tensor of same rank as activation with the last dimension being 1.\n",
    "    \"\"\"\n",
    "    return ComputeNormalization.apply(activations, t, num_iters)\n",
    "\n",
    "def tempered_sigmoid(activations, t, num_iters = 5):\n",
    "    \"\"\"Tempered sigmoid function.\n",
    "    Args:\n",
    "      activations: Activations for the positive class for binary classification.\n",
    "      t: Temperature tensor > 0.0.\n",
    "      num_iters: Number of iterations to run the method.\n",
    "    Returns:\n",
    "      A probabilities tensor.\n",
    "    \"\"\"\n",
    "    internal_activations = torch.stack([activations,\n",
    "        torch.zeros_like(activations)],\n",
    "        dim=-1)\n",
    "    internal_probabilities = tempered_softmax(internal_activations, t, num_iters)\n",
    "    return internal_probabilities[..., 0]\n",
    "\n",
    "\n",
    "def tempered_softmax(activations, t, num_iters=5):\n",
    "    \"\"\"Tempered softmax function.\n",
    "    Args:\n",
    "      activations: A multi-dimensional tensor with last dimension `num_classes`.\n",
    "      t: Temperature > 1.0.\n",
    "      num_iters: Number of iterations to run the method.\n",
    "    Returns:\n",
    "      A probabilities tensor.\n",
    "    \"\"\"\n",
    "    if t == 1.0:\n",
    "        return activations.softmax(dim=-1)\n",
    "\n",
    "    normalization_constants = compute_normalization(activations, t, num_iters)\n",
    "    return exp_t(activations - normalization_constants, t)\n",
    "\n",
    "def bi_tempered_binary_logistic_loss(activations,\n",
    "        labels,\n",
    "        t1,\n",
    "        t2,\n",
    "        label_smoothing = 0.0,\n",
    "        num_iters=5,\n",
    "        reduction='mean'):\n",
    "\n",
    "    \"\"\"Bi-Tempered binary logistic loss.\n",
    "    Args:\n",
    "      activations: A tensor containing activations for class 1.\n",
    "      labels: A tensor with shape as activations, containing probabilities for class 1\n",
    "      t1: Temperature 1 (< 1.0 for boundedness).\n",
    "      t2: Temperature 2 (> 1.0 for tail heaviness, < 1.0 for finite support).\n",
    "      label_smoothing: Label smoothing\n",
    "      num_iters: Number of iterations to run the method.\n",
    "    Returns:\n",
    "      A loss tensor.\n",
    "    \"\"\"\n",
    "    internal_activations = torch.stack([activations,\n",
    "        torch.zeros_like(activations)],\n",
    "        dim=-1)\n",
    "    internal_labels = torch.stack([labels.to(activations.dtype),\n",
    "        1.0 - labels.to(activations.dtype)],\n",
    "        dim=-1)\n",
    "    return bi_tempered_logistic_loss(internal_activations, \n",
    "            internal_labels,\n",
    "            t1,\n",
    "            t2,\n",
    "            label_smoothing = label_smoothing,\n",
    "            num_iters = num_iters,\n",
    "            reduction = reduction)\n",
    "\n",
    "def bi_tempered_logistic_loss(activations,\n",
    "        labels,\n",
    "        t1,\n",
    "        t2,\n",
    "        label_smoothing=0.0,\n",
    "        num_iters=5,\n",
    "        reduction = 'mean'):\n",
    "\n",
    "    \"\"\"Bi-Tempered Logistic Loss.\n",
    "    Args:\n",
    "      activations: A multi-dimensional tensor with last dimension `num_classes`.\n",
    "      labels: A tensor with shape and dtype as activations (onehot), \n",
    "        or a long tensor of one dimension less than activations (pytorch standard)\n",
    "      t1: Temperature 1 (< 1.0 for boundedness).\n",
    "      t2: Temperature 2 (> 1.0 for tail heaviness, < 1.0 for finite support).\n",
    "      label_smoothing: Label smoothing parameter between [0, 1). Default 0.0.\n",
    "      num_iters: Number of iterations to run the method. Default 5.\n",
    "      reduction: ``'none'`` | ``'mean'`` | ``'sum'``. Default ``'mean'``.\n",
    "        ``'none'``: No reduction is applied, return shape is shape of\n",
    "        activations without the last dimension.\n",
    "        ``'mean'``: Loss is averaged over minibatch. Return shape (1,)\n",
    "        ``'sum'``: Loss is summed over minibatch. Return shape (1,)\n",
    "    Returns:\n",
    "      A loss tensor.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(labels.shape)<len(activations.shape): #not one-hot\n",
    "        labels_onehot = torch.zeros_like(activations)\n",
    "        labels_onehot.scatter_(1, labels[..., None], 1)\n",
    "    else:\n",
    "        labels_onehot = labels\n",
    "\n",
    "    if label_smoothing > 0:\n",
    "        num_classes = labels_onehot.shape[-1]\n",
    "        labels_onehot = ( 1 - label_smoothing * num_classes / (num_classes - 1) ) \\\n",
    "                * labels_onehot + \\\n",
    "                label_smoothing / (num_classes - 1)\n",
    "\n",
    "    probabilities = tempered_softmax(activations, t2, num_iters)\n",
    "\n",
    "    loss_values = labels_onehot * log_t(labels_onehot + 1e-10, t1) \\\n",
    "            - labels_onehot * log_t(probabilities, t1) \\\n",
    "            - labels_onehot.pow(2.0 - t1) / (2.0 - t1) \\\n",
    "            + probabilities.pow(2.0 - t1) / (2.0 - t1)\n",
    "    loss_values = loss_values.sum(dim = -1) #sum over classes\n",
    "\n",
    "    if reduction == 'none':\n",
    "        return loss_values\n",
    "    if reduction == 'sum':\n",
    "        return loss_values.sum()\n",
    "    if reduction == 'mean':\n",
    "        return loss_values.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiTemperedLogisticLoss(nn.Module): \n",
    "    def __init__(self, t1, t2, smoothing=0.0): \n",
    "        super(BiTemperedLogisticLoss, self).__init__() \n",
    "        self.t1 = t1\n",
    "        self.t2 = t2\n",
    "        self.smoothing = smoothing\n",
    "    def forward(self, logit_label, truth_label):\n",
    "        loss_label = bi_tempered_logistic_loss(\n",
    "            logit_label, truth_label,\n",
    "            t1=self.t1, t2=self.t2,\n",
    "            label_smoothing=self.smoothing,\n",
    "            reduction='none'\n",
    "        )\n",
    "        \n",
    "        loss_label = loss_label.mean()\n",
    "        return loss_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaylorSoftmax(nn.Module):\n",
    "    '''\n",
    "    This is the autograd version\n",
    "    '''\n",
    "    def __init__(self, dim=1, n=2):\n",
    "        super(TaylorSoftmax, self).__init__()\n",
    "        assert n % 2 == 0\n",
    "        self.dim = dim\n",
    "        self.n = n\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        usage similar to nn.Softmax:\n",
    "            >>> mod = TaylorSoftmax(dim=1, n=4)\n",
    "            >>> inten = torch.randn(1, 32, 64, 64)\n",
    "            >>> out = mod(inten)\n",
    "        '''\n",
    "        fn = torch.ones_like(x)\n",
    "        denor = 1.\n",
    "        for i in range(1, self.n+1):\n",
    "            denor *= i\n",
    "            fn = fn + x.pow(i) / denor\n",
    "        out = fn / fn.sum(dim=self.dim, keepdims=True)\n",
    "        return out\n",
    "\n",
    "    \n",
    "class TaylorCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, n=2, ignore_index=-1, reduction='mean', smoothing=0.05):\n",
    "        super(TaylorCrossEntropyLoss, self).__init__()\n",
    "        assert n % 2 == 0\n",
    "        self.taylor_softmax = TaylorSoftmax(dim=1, n=n)\n",
    "        self.reduction = reduction\n",
    "        self.ignore_index = ignore_index\n",
    "        self.lab_smooth = LabelSmoothingLoss(5, smoothing=smoothing)\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        log_probs = self.taylor_softmax(logits).log()\n",
    "        #loss = F.nll_loss(log_probs, labels, reduction=self.reduction,\n",
    "        #        ignore_index=self.ignore_index)\n",
    "        loss = self.lab_smooth(log_probs, labels)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = OurModel(5).cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)#, weight_decay=1e-3, amsgrad=False)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1)\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size = 16, shuffle= True, num_workers=4, pin_memory=True, drop_last=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size = 16, shuffle=False, num_workers=4, pin_memory=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fine-tuning...\n"
     ]
    }
   ],
   "source": [
    "print('Start fine-tuning...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader):\n",
    "    epoch_loss = 0.\n",
    "    model.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1000)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        epoch_loss += loss\n",
    "        \n",
    "        if (i+1)%100==0:\n",
    "            time_diff = get_run_time(start_time)\n",
    "            print('Epoch [{}/{}]: Iter {}, Loss {:.4f}, Runtime {:.0f}m {:.0f}s'.format(epoch + 1, num_epochs, i + 1, loss, time_diff//60, time_diff%60))\n",
    "            \n",
    "    return epoch_loss/(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(images)\n",
    "            \n",
    "        outputs = outputs.softmax(1)\n",
    "        \n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        correct += (prediction == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return correct/total * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_run_time(start_time):\n",
    "    end_time = time.time()\n",
    "    runtime = end_time - start_time\n",
    "    return runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]: Iter 100, Loss 0.9597, Runtime 0m 46s\n",
      "Epoch [1/20]: Iter 200, Loss 0.3463, Runtime 1m 31s\n",
      "Epoch [1/20]: Iter 300, Loss 0.2658, Runtime 2m 15s\n",
      "Epoch [1/20]: Iter 400, Loss 0.5642, Runtime 2m 60s\n",
      "Epoch [1/20]: Iter 500, Loss 0.3686, Runtime 3m 44s\n",
      "Epoch [1/20]: Iter 600, Loss 0.4562, Runtime 4m 28s\n",
      "Epoch [1/20]: Iter 700, Loss 0.6086, Runtime 5m 13s\n",
      "Epoch [1/20]: Iter 800, Loss 0.3930, Runtime 5m 57s\n",
      "Epoch [1/20]: Iter 900, Loss 0.2643, Runtime 6m 42s\n",
      "Testing on test dataset...\n",
      "Epoch [1/20] Loss: 0.5012 Test_Acc: 85.0000\n",
      "The accuracy is improved, save model\n",
      "Epoch [2/20]: Iter 100, Loss 0.1235, Runtime 11m 7s\n",
      "Epoch [2/20]: Iter 200, Loss 0.2691, Runtime 11m 51s\n",
      "Epoch [2/20]: Iter 300, Loss 0.4457, Runtime 12m 35s\n",
      "Epoch [2/20]: Iter 400, Loss 0.4351, Runtime 13m 20s\n",
      "Epoch [2/20]: Iter 500, Loss 0.3902, Runtime 14m 4s\n",
      "Epoch [2/20]: Iter 600, Loss 0.1156, Runtime 14m 48s\n",
      "Epoch [2/20]: Iter 700, Loss 0.5080, Runtime 15m 33s\n",
      "Epoch [2/20]: Iter 800, Loss 0.3021, Runtime 16m 17s\n",
      "Epoch [2/20]: Iter 900, Loss 0.2368, Runtime 17m 2s\n",
      "Testing on test dataset...\n",
      "Epoch [2/20] Loss: 0.3892 Test_Acc: 88.0841\n",
      "The accuracy is improved, save model\n",
      "Epoch [3/20]: Iter 100, Loss 0.3411, Runtime 21m 27s\n",
      "Epoch [3/20]: Iter 200, Loss 0.3488, Runtime 22m 11s\n",
      "Epoch [3/20]: Iter 300, Loss 0.4629, Runtime 22m 55s\n",
      "Epoch [3/20]: Iter 400, Loss 0.7041, Runtime 23m 40s\n",
      "Epoch [3/20]: Iter 500, Loss 0.4764, Runtime 24m 24s\n",
      "Epoch [3/20]: Iter 600, Loss 0.4429, Runtime 25m 8s\n",
      "Epoch [3/20]: Iter 700, Loss 0.0499, Runtime 25m 53s\n",
      "Epoch [3/20]: Iter 800, Loss 0.0877, Runtime 26m 37s\n",
      "Epoch [3/20]: Iter 900, Loss 0.1998, Runtime 27m 22s\n",
      "Testing on test dataset...\n",
      "Epoch [3/20] Loss: 0.3556 Test_Acc: 86.9315\n",
      "Epoch [4/20]: Iter 100, Loss 0.3817, Runtime 31m 46s\n",
      "Epoch [4/20]: Iter 200, Loss 0.3263, Runtime 32m 31s\n",
      "Epoch [4/20]: Iter 300, Loss 1.0481, Runtime 33m 15s\n",
      "Epoch [4/20]: Iter 400, Loss 0.2548, Runtime 33m 60s\n",
      "Epoch [4/20]: Iter 500, Loss 0.1283, Runtime 34m 44s\n",
      "Epoch [4/20]: Iter 600, Loss 0.1626, Runtime 35m 29s\n",
      "Epoch [4/20]: Iter 700, Loss 0.3947, Runtime 36m 13s\n",
      "Epoch [4/20]: Iter 800, Loss 0.4743, Runtime 36m 58s\n",
      "Epoch [4/20]: Iter 900, Loss 0.5873, Runtime 37m 42s\n",
      "Testing on test dataset...\n",
      "Epoch [4/20] Loss: 0.3331 Test_Acc: 86.6978\n",
      "Epoch [5/20]: Iter 100, Loss 0.5919, Runtime 42m 7s\n",
      "Epoch [5/20]: Iter 200, Loss 0.1871, Runtime 42m 52s\n",
      "Epoch [5/20]: Iter 300, Loss 0.5883, Runtime 43m 36s\n",
      "Epoch [5/20]: Iter 400, Loss 0.4605, Runtime 44m 20s\n",
      "Epoch [5/20]: Iter 500, Loss 0.4424, Runtime 45m 5s\n",
      "Epoch [5/20]: Iter 600, Loss 0.1856, Runtime 45m 49s\n",
      "Epoch [5/20]: Iter 700, Loss 0.2760, Runtime 46m 34s\n",
      "Epoch [5/20]: Iter 800, Loss 0.2743, Runtime 47m 18s\n",
      "Epoch [5/20]: Iter 900, Loss 0.1073, Runtime 48m 2s\n",
      "Testing on test dataset...\n",
      "Epoch [5/20] Loss: 0.3099 Test_Acc: 87.6012\n",
      "Epoch [6/20]: Iter 100, Loss 0.4636, Runtime 52m 27s\n",
      "Epoch [6/20]: Iter 200, Loss 0.1557, Runtime 53m 12s\n",
      "Epoch [6/20]: Iter 300, Loss 0.1988, Runtime 53m 56s\n",
      "Epoch [6/20]: Iter 400, Loss 0.4818, Runtime 54m 40s\n",
      "Epoch [6/20]: Iter 500, Loss 0.1055, Runtime 55m 25s\n",
      "Epoch [6/20]: Iter 600, Loss 0.3685, Runtime 56m 9s\n",
      "Epoch [6/20]: Iter 700, Loss 0.1028, Runtime 56m 53s\n",
      "Epoch [6/20]: Iter 800, Loss 0.4688, Runtime 57m 38s\n",
      "Epoch [6/20]: Iter 900, Loss 0.2768, Runtime 58m 22s\n",
      "Testing on test dataset...\n",
      "Epoch [6/20] Loss: 0.2921 Test_Acc: 86.0748\n",
      "Epoch [7/20]: Iter 100, Loss 0.4796, Runtime 62m 47s\n",
      "Epoch [7/20]: Iter 200, Loss 0.1088, Runtime 63m 32s\n",
      "Epoch [7/20]: Iter 300, Loss 0.2694, Runtime 64m 16s\n",
      "Epoch [7/20]: Iter 400, Loss 0.0689, Runtime 65m 0s\n",
      "Epoch [7/20]: Iter 500, Loss 0.2544, Runtime 65m 45s\n",
      "Epoch [7/20]: Iter 600, Loss 0.0709, Runtime 66m 29s\n",
      "Epoch [7/20]: Iter 700, Loss 0.1943, Runtime 67m 13s\n",
      "Epoch [7/20]: Iter 800, Loss 0.4773, Runtime 67m 58s\n",
      "Epoch [7/20]: Iter 900, Loss 0.0844, Runtime 68m 42s\n",
      "Testing on test dataset...\n",
      "Epoch [7/20] Loss: 0.2685 Test_Acc: 87.5545\n",
      "Epoch [8/20]: Iter 100, Loss 0.0951, Runtime 73m 7s\n",
      "Epoch [8/20]: Iter 200, Loss 0.4627, Runtime 73m 51s\n",
      "Epoch [8/20]: Iter 300, Loss 0.5331, Runtime 74m 36s\n",
      "Epoch [8/20]: Iter 400, Loss 0.2354, Runtime 75m 20s\n",
      "Epoch [8/20]: Iter 500, Loss 0.6400, Runtime 76m 4s\n",
      "Epoch [8/20]: Iter 600, Loss 0.1570, Runtime 76m 49s\n",
      "Epoch [8/20]: Iter 700, Loss 0.1839, Runtime 77m 33s\n",
      "Epoch [8/20]: Iter 800, Loss 0.0511, Runtime 78m 17s\n",
      "Epoch [8/20]: Iter 900, Loss 0.8499, Runtime 79m 2s\n",
      "Testing on test dataset...\n",
      "Epoch [8/20] Loss: 0.2457 Test_Acc: 87.0249\n",
      "Epoch [9/20]: Iter 100, Loss 0.3734, Runtime 83m 27s\n",
      "Epoch [9/20]: Iter 200, Loss 0.1764, Runtime 84m 11s\n",
      "Epoch [9/20]: Iter 300, Loss 0.0219, Runtime 84m 56s\n",
      "Epoch [9/20]: Iter 400, Loss 0.1400, Runtime 85m 40s\n",
      "Epoch [9/20]: Iter 500, Loss 0.3860, Runtime 86m 24s\n",
      "Epoch [9/20]: Iter 600, Loss 0.2434, Runtime 87m 9s\n",
      "Epoch [9/20]: Iter 700, Loss 0.0348, Runtime 87m 53s\n",
      "Epoch [9/20]: Iter 800, Loss 0.1924, Runtime 88m 37s\n",
      "Epoch [9/20]: Iter 900, Loss 0.2321, Runtime 89m 22s\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0.\n",
    "best_epoch = None\n",
    "end_patient = 0\n",
    "num_epochs = 20\n",
    "\n",
    "save_model_path = ''\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    train_loss = train_model(model, train_loader)\n",
    "    train_acc = test_model(model, train_loader)\n",
    "\n",
    "    \n",
    "    print('Testing on test dataset...')\n",
    "    test_acc = test_model(model, test_loader)\n",
    "    print('Epoch [{}/{}] Loss: {:.4f} Test_Acc: {:.4f}'\n",
    "          .format(epoch + 1, num_epochs, train_loss, test_acc))\n",
    "    \n",
    "    #scheduler.step()\n",
    "    \n",
    "    train_accuracy.append(train_acc)\n",
    "    test_accuracy.append(test_acc)\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        best_epoch = epoch + 1\n",
    "        print('The accuracy is improved, save model')\n",
    "        torch.save(model.state_dict(), os.path.join(\n",
    "                                                    'resnext50_tuning_epoch_%d_acc_%g.pth' %\n",
    "                                                    (best_epoch, best_acc)))\n",
    "\n",
    "print('After the training, the end of the epoch %d, the accuracy %g is the highest' % (best_epoch, best_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1,31),train_accuracy,label='Train Accuracy')\n",
    "plt.plot(np.arange(1,31),test_accuracy,label='Test Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Versus Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = OurModel(5).to(device)\n",
    "model.load_state_dict(torch.load('resnext50_tuning_epoch_20_acc_87.1807.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nb_classes = 5\n",
    "\n",
    "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(test_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        #print(classes)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=True,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm/ np.sum(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2%' #if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "num_classes=5\n",
    "M = confusion_matrix.numpy()\n",
    "plot_confusion_matrix(M, classes=np.arange(num_classes), normalize=True)\n",
    "print(\"Accuracy:\",np.trace(M/np.sum(M)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
