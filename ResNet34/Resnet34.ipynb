{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !nvidia-smi\n",
    "# !pip install prefetch_generator\n",
    "# !pip install timm\n",
    "# !pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import cv2\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import Resize, ToTensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "import torchvision\n",
    "import boto3\n",
    "import io\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import tempfile\n",
    "import PIL\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from prefetch_generator import BackgroundGenerator\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from sklearn import model_selection, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're using: cuda\n"
     ]
    }
   ],
   "source": [
    "# Make sure you're using cuda (GPU) by checking the hardware accelerator under Runtime -> Change runtime type\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"We're using:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Download dataset from AWS S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists: Dataset\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"Dataset\"\n",
    "if not os.path.exists(dataset_name):\n",
    "    !pip install cloudpathlib[s3,gs,azure]\n",
    "    from cloudpathlib import CloudPath\n",
    "    cp = CloudPath(\"s3://cassavaproject\")\n",
    "    cp.download_to(\"./\" + dataset_name)\n",
    "else:\n",
    "    print(f\"File exists: {dataset_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.image_path = 'Dataset/train_images'\n",
    "        self.labels = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = self.image_path + '/' + self.labels.iloc[idx]['image_id']\n",
    "\n",
    "        # Read the image from the file path\n",
    "        #image = Image.open(img_name)\n",
    "        image = cv2.imread(img_name)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        #image = torchvision.io.read_file(img_name)\n",
    "        #image = torchvision.io.decode_jpeg(image, device=\"cpu\")\n",
    "        #image = image.float().\n",
    "        \n",
    "        # Transform the image using self.transform\n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "\n",
    "        if \"label\" in self.labels.columns:\n",
    "            label = self.labels.iloc[idx]['label']\n",
    "            sample = (image, label)\n",
    "        else:\n",
    "            sample = (image)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Used for directly download and read file from AWS S3.\n",
    "#If running the download cell above, use 'MyDataset' class instead of this one.\n",
    "class MyDatasetS3(Dataset):\n",
    "\n",
    "    def __init__(self, df, transform=None):\n",
    "        #File path for csv and images\n",
    "        self.image_path = 'train_images'\n",
    "        \n",
    "        #Connect to s3 file\n",
    "        self.csv_path = df\n",
    "        self.s3_client = boto3.resource('s3')\n",
    "        self.bucket = self.s3_client.Bucket('cassavaproject')\n",
    "        \n",
    "        s3 = boto3.client('s3')\n",
    "        obj = s3.get_object(Bucket = 'cassavaproject',Key = 'train.csv')\n",
    "\n",
    "        self.labels = pd.read_csv(obj['Body'])\n",
    "        \n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        img_name = self.image_path + '/' + self.labels.iloc[idx]['image_id']\n",
    "        \n",
    "        # we can download the file from S3 to a temporary file locally, then store that opened file as our image variable.\n",
    "        # we need to create the local file name\n",
    "        obj = self.bucket.Object(img_name)\n",
    "        tmp = tempfile.NamedTemporaryFile()\n",
    "        tmp_name = '{}.jpg'.format(tmp.name)\n",
    "\n",
    "        # now we can actually download from S3 to a local place\n",
    "        with open(tmp_name, 'wb') as f:\n",
    "            obj.download_fileobj(f)\n",
    "            f.flush()\n",
    "            f.close()\n",
    "            \n",
    "            image = torchvision.io.read_file(tmp_name)\n",
    "            image = torchvision.io.decode_jpeg(image, device=\"cpu\")\n",
    "            image = image.float()\n",
    "            \n",
    "        # Transform the image using self.transform\n",
    "        if self.transform:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "\n",
    "        if \"label\" in self.labels.columns:\n",
    "            label = self.labels.iloc[idx]['label']\n",
    "            sample = (image, label)\n",
    "        else:\n",
    "            sample = (image)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Credit: https://www.kaggle.com/code/aliabdin1/calculate-mean-std-of-images/notebook\n",
    "mean = np.array([0.42984136, 0.49624753, 0.3129598 ])\n",
    "std = np.array([0.21417203, 0.21910103, 0.19542212])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transform = torch.nn.Sequential(transforms.Resize((256,256),antialias=True), \n",
    "                                      transforms.Normalize(mean=mean,std=std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "albu_transform_train = A.Compose(\n",
    "        [A.CenterCrop(height=256, width=256), \n",
    "         A.HorizontalFlip(p=0.5),\n",
    "         A.VerticalFlip(p=0.5),\n",
    "         A.RandomRotate90(p=0.5),\n",
    "         A.RandomBrightnessContrast(p=0.8), \n",
    "         A.CoarseDropout(p=0.5),\n",
    "         A.Normalize(mean=mean, std=std),\n",
    "         ToTensorV2()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "albu_transform_test = A.Compose(\n",
    "        [A.CenterCrop(height=256, width=256),\n",
    "         A.Normalize(mean=mean, std=std),\n",
    "         ToTensorV2()\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Dataset/train.csv')\n",
    "\n",
    "train_df, test_df = model_selection.train_test_split(\n",
    "    df, test_size=0.3, random_state=42, stratify=df.label.values\n",
    ")\n",
    "\n",
    "train_data = MyDataset(train_df, transform = albu_transform_train)\n",
    "test_data = MyDataset(test_df, transform = albu_transform_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# timm.list_models('*resnet*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnet34d_ra2-f8dcfcaf.pth',\n",
       " 'num_classes': 1000,\n",
       " 'input_size': (3, 224, 224),\n",
       " 'pool_size': (7, 7),\n",
       " 'crop_pct': 0.875,\n",
       " 'interpolation': 'bicubic',\n",
       " 'mean': (0.485, 0.456, 0.406),\n",
       " 'std': (0.229, 0.224, 0.225),\n",
       " 'first_conv': 'conv1.0',\n",
       " 'classifier': 'fc',\n",
       " 'architecture': 'resnet34d'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model = timm.create_model('resnet34d', pretrained=True)\n",
    "test_model.default_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class OurModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(OurModel, self).__init__()\n",
    "        self.model = timm.create_model('resnet34d', pretrained=True) #torchvision.models.resnet34(weights='IMAGENET1K_V1')\n",
    "        self.drop = nn.Dropout(p=0.2)\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "        self.softmax = nn.Softmax()\n",
    "    def forward(self, input):\n",
    "        out = self.model(input)\n",
    "        out = self.drop(out)\n",
    "        softmax = self.softmax(out)\n",
    "        return softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = OurModel(5).cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), \n",
    "                             lr=2e-5, weight_decay=1e-6, \n",
    "                             amsgrad=False) #torch.optim.Adam(model.parameters(), lr=5*1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataLoaderX(DataLoader):\n",
    "\n",
    "    def __iter__(self):\n",
    "        return BackgroundGenerator(super().__iter__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoaderX(dataset=train_data, batch_size = 64, shuffle= True, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoaderX(dataset=test_data, batch_size = 64, shuffle=False, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start fine-tuning...\n"
     ]
    }
   ],
   "source": [
    "print('Start fine-tuning...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_model(model, test_loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            _,prediction = torch.max(outputs.data, 1)\n",
    "            correct += (prediction == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        model.train()\n",
    "        return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_run_time(start_time):\n",
    "    end_time = time.time()\n",
    "    runtime = end_time - start_time\n",
    "    return runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]/tmp/ipykernel_17912/3494929337.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  softmax = self.softmax(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [02:05<1:42:08, 125.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] Loss: 337.7293 Train_Acc: 51.4055  Test_Acc: 67.8660\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [04:04<1:37:16, 121.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50] Loss: 300.1760 Train_Acc: 62.7629  Test_Acc: 71.1682\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [06:00<1:33:19, 119.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50] Loss: 289.7029 Train_Acc: 66.2482  Test_Acc: 75.7944\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 4/50 [07:56<1:30:19, 117.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50] Loss: 279.1073 Train_Acc: 71.1357  Test_Acc: 79.0187\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 5/50 [09:53<1:28:16, 117.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50] Loss: 273.0162 Train_Acc: 73.1856  Test_Acc: 80.9034\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 6/50 [11:51<1:26:24, 117.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50] Loss: 269.0841 Train_Acc: 73.8466  Test_Acc: 81.2617\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 7/50 [13:51<1:24:48, 118.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50] Loss: 267.8763 Train_Acc: 74.6144  Test_Acc: 82.0405\n",
      "The accuracy is improved, save model\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 8/50 [15:47<1:22:18, 117.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50] Loss: 265.9839 Train_Acc: 75.3555  Test_Acc: 82.6791\n",
      "The accuracy is improved, save model\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 9/50 [17:42<1:19:54, 116.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50] Loss: 264.0577 Train_Acc: 75.6026  Test_Acc: 82.7570\n",
      "The accuracy is improved, save model\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 10/50 [19:38<1:17:38, 116.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50] Loss: 261.2299 Train_Acc: 76.9313  Test_Acc: 82.6012\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 11/50 [21:37<1:16:12, 117.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50] Loss: 260.4499 Train_Acc: 77.2050  Test_Acc: 83.2710\n",
      "The accuracy is improved, save model\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 12/50 [23:38<1:15:00, 118.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50] Loss: 260.3889 Train_Acc: 77.5923  Test_Acc: 83.3801\n",
      "The accuracy is improved, save model\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 13/50 [25:35<1:12:43, 117.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50] Loss: 257.7202 Train_Acc: 78.3001  Test_Acc: 83.1931\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 14/50 [27:28<1:09:57, 116.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50] Loss: 258.3557 Train_Acc: 78.4470  Test_Acc: 82.8349\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 15/50 [29:25<1:08:03, 116.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50] Loss: 257.3884 Train_Acc: 78.5404  Test_Acc: 83.2087\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 16/50 [31:23<1:06:24, 117.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50] Loss: 257.5786 Train_Acc: 78.7407  Test_Acc: 83.1464\n",
      "Epoch 00016: reducing learning rate of group 0 to 4.0000e-06.\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 17/50 [33:24<1:05:06, 118.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50] Loss: 255.1003 Train_Acc: 79.3684  Test_Acc: 83.6604\n",
      "The accuracy is improved, save model\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 18/50 [35:22<1:02:57, 118.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50] Loss: 255.0617 Train_Acc: 79.2415  Test_Acc: 83.7539\n",
      "The accuracy is improved, save model\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 19/50 [37:19<1:00:54, 117.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/50] Loss: 256.6276 Train_Acc: 79.1480  Test_Acc: 83.9408\n",
      "The accuracy is improved, save model\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 20/50 [39:17<58:53, 117.79s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50] Loss: 254.8660 Train_Acc: 79.3417  Test_Acc: 83.6449\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 21/50 [41:17<57:20, 118.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50] Loss: 255.3495 Train_Acc: 79.8958  Test_Acc: 83.9252\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 22/50 [43:18<55:40, 119.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50] Loss: 255.9847 Train_Acc: 79.2949  Test_Acc: 83.5826\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 23/50 [45:16<53:30, 118.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/50] Loss: 253.9930 Train_Acc: 80.1896  Test_Acc: 84.0966\n",
      "The accuracy is improved, save model\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 24/50 [47:11<51:00, 117.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50] Loss: 254.7750 Train_Acc: 80.1896  Test_Acc: 84.2368\n",
      "The accuracy is improved, save model\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 25/50 [49:08<48:53, 117.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50] Loss: 254.5698 Train_Acc: 79.6955  Test_Acc: 83.9097\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 26/50 [51:07<47:10, 117.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/50] Loss: 254.0963 Train_Acc: 80.0561  Test_Acc: 83.4268\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 27/50 [53:10<45:46, 119.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50] Loss: 254.4253 Train_Acc: 80.1162  Test_Acc: 83.8006\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [55:08<43:39, 119.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50] Loss: 255.2417 Train_Acc: 79.6288  Test_Acc: 84.0810\n",
      "Epoch 00028: reducing learning rate of group 0 to 8.0000e-07.\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 29/50 [57:04<41:20, 118.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50] Loss: 254.0165 Train_Acc: 80.1562  Test_Acc: 83.3333\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 30/50 [58:58<38:57, 116.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/50] Loss: 252.6462 Train_Acc: 80.8707  Test_Acc: 84.1433\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 31/50 [1:00:56<37:06, 117.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50] Loss: 253.1036 Train_Acc: 80.4634  Test_Acc: 83.8006\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 32/50 [1:02:55<35:18, 117.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50] Loss: 253.0457 Train_Acc: 80.1562  Test_Acc: 83.5981\n",
      "Epoch 00032: reducing learning rate of group 0 to 1.6000e-07.\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 33/50 [1:04:50<33:07, 116.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50] Loss: 254.2352 Train_Acc: 80.2831  Test_Acc: 84.1745\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 34/50 [1:06:43<30:54, 115.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50] Loss: 252.7755 Train_Acc: 80.4300  Test_Acc: 83.9875\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 35/50 [1:08:39<28:58, 115.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50] Loss: 253.2852 Train_Acc: 80.1429  Test_Acc: 83.8006\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 36/50 [1:10:37<27:10, 116.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50] Loss: 253.1950 Train_Acc: 80.2965  Test_Acc: 84.1121\n",
      "Epoch 00036: reducing learning rate of group 0 to 3.2000e-08.\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 37/50 [1:12:36<25:23, 117.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50] Loss: 254.3676 Train_Acc: 80.0093  Test_Acc: 84.0187\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 38/50 [1:14:30<23:13, 116.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50] Loss: 253.2204 Train_Acc: 80.0961  Test_Acc: 84.0498\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 39/50 [1:16:23<21:10, 115.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50] Loss: 254.5271 Train_Acc: 79.9893  Test_Acc: 84.1277\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 40/50 [1:18:20<19:16, 115.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50] Loss: 254.9133 Train_Acc: 79.7890  Test_Acc: 84.3614\n",
      "The accuracy is improved, save model\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 41/50 [1:20:18<17:29, 116.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50] Loss: 254.4558 Train_Acc: 79.9025  Test_Acc: 84.2835\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 42/50 [1:22:17<15:38, 117.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50] Loss: 253.8401 Train_Acc: 80.3232  Test_Acc: 84.1745\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 43/50 [1:23:56<13:02, 111.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50] Loss: 254.2200 Train_Acc: 80.0961  Test_Acc: 84.4237\n",
      "The accuracy is improved, save model\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 44/50 [1:25:18<10:17, 102.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50] Loss: 253.3810 Train_Acc: 80.5101  Test_Acc: 83.9720\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 45/50 [1:26:41<08:03, 96.68s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50] Loss: 254.3880 Train_Acc: 79.9960  Test_Acc: 84.1745\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 46/50 [1:28:03<06:09, 92.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50] Loss: 254.1576 Train_Acc: 80.0294  Test_Acc: 83.8941\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 47/50 [1:29:24<04:27, 89.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50] Loss: 253.3690 Train_Acc: 80.3833  Test_Acc: 83.7383\n",
      "Epoch 00047: reducing learning rate of group 0 to 6.4000e-09.\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 48/50 [1:30:47<02:54, 87.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50] Loss: 254.1409 Train_Acc: 80.1696  Test_Acc: 84.1277\n",
      "Testing on test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 49/50 [1:32:09<01:25, 85.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50] Loss: 253.3171 Train_Acc: 80.0294  Test_Acc: 84.1277\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0.\n",
    "best_epoch = None\n",
    "end_patient = 0\n",
    "num_epochs = 50\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.2, patience=3, verbose=True)\n",
    "\n",
    "save_model_path = ''\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "for epoch in trange(num_epochs):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    epoch_loss = 0.\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss\n",
    "        _, prediction = torch.max(outputs.data, 1)\n",
    "        correct += (prediction == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        time_diff = get_run_time(start_time)\n",
    "\n",
    "        # print('Epoch [{}/{}]: Iter {}, Loss {:.4f}, Runtime {:.0f}m {:.0f}s'.format(epoch + 1, num_epochs, i + 1, loss, time_diff//60, time_diff%60))\n",
    "        train_loss.append(loss)\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    print('Testing on test dataset...')\n",
    "    test_acc = test_model(model, test_loader)\n",
    "    print('Epoch [{}/{}] Loss: {:.4f} Train_Acc: {:.4f}  Test_Acc: {:.4f}'\n",
    "          .format(epoch + 1, num_epochs, epoch_loss, train_acc, test_acc))\n",
    "    scheduler.step(test_acc)\n",
    "    train_accuracy.append(train_acc)\n",
    "    test_accuracy.append(test_acc)\n",
    "    if (test_acc > best_acc) & (test_acc >82):\n",
    "        best_acc = test_acc\n",
    "        best_epoch = epoch + 1\n",
    "        print('The accuracy is improved, save model')\n",
    "        torch.save(model.state_dict(), os.path.join(\n",
    "                                                    'resnet34_acc_%g.pth' %\n",
    "                                                    (best_acc)))\n",
    "\n",
    "print('After the training, the end of the epoch %d, the accuracy %g is the highest' % (best_epoch, best_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Result Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1,len(train_accuracy)+1),train_accuracy,label='Train Accuracy')\n",
    "plt.plot(np.arange(1,len(test_accuracy)+1),test_accuracy,label='Test Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Resnet34 Accuracy Versus Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nb_classes = 5\n",
    "\n",
    "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(test_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        #print(classes)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=True,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm/ np.sum(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2%' #if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "num_classes=5\n",
    "M = confusion_matrix.numpy()\n",
    "plot_confusion_matrix(M, classes=np.arange(num_classes), \n",
    "                      normalize=True,title=\"Resnet34 Confusion Matrix\")\n",
    "print(\"Accuracy:\",np.trace(M/np.sum(M)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
